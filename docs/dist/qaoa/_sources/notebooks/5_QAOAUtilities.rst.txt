.. _5-QAOAUtilities: 


Utility functions for QAOA
==========================

This section walks through some of the key features provided in
EntropicaQAOA, all of which are contained in the ``utilities.py`` file.
In particular, it illustrates the integration of functionalities from
common graph and data analysis packages such as NetworkX and Pandas. We
also provide two examples that bring together the functionalities to
solve real problems.

.. code:: ipython3

    # The usual combination of imports from numpy, scipy and matplotlib
    from scipy.optimize import minimize
    import numpy as np
    import matplotlib.pyplot as plt
    
    # import QAOA Parameter classes 
    from entropica_qaoa.qaoa.parameters import ExtendedParams, StandardParams
    
    # Cost functions and all the utilities
    from entropica_qaoa.qaoa.cost_function import QAOACostFunctionOnWFSim
    from entropica_qaoa.utilities import *
    
    # Matplotlib raises errors about NetworkX using outdated methods. Nothing we can change, so we suppress the messages.
    import warnings
    warnings.filterwarnings('ignore')

Hamiltonians and graphs
-----------------------

In QAOA, a problem instance is defined by its corresponding
*hyperparameters*, which refers to a specification of the total number
of qubits ``nqubits``, and one or both of the following:

1. The single qubits that have a bias term (denoted ``singles``) and the
   corresponding bias coefficients (denoted ``biases``).
2. The pairs of qubits that are coupled (denoted ``pairs``), and the
   corresponding coupling coefficients (denoted ``couplings``).

Equivalently, when viewed as a network graph problem, a QAOA instance is
defined by specifying the total number of vertices or nodes in the
graph, and one or both of the following:

1. The vertices that have a bias term, and the corresponding bias
   coefficients.
2. The pairs of vertices that are connected by an edge, and the
   corresponding edge weight.

The following sections explain how EntropicaQAOA’s utility functions
allow for the simple creation of, and conversion between, Hamiltonians
and graphs.

Hyperparameters to Hamiltonian
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

If we have a known set of problem hyperparameters, the
``hamiltonian_from_hyperparams()`` method allows us to easily create the
corresponding Hamiltonian.

.. code:: ipython3

    # Specify some hyperparameters
    nqubits = 3
    singles = [1]
    biases = [0.3]
    pairs = [[0,1], [1,2]]
    couplings = [0.4, 0.6]
    
    # Create the Hamiltonian
    h0 = hamiltonian_from_hyperparams(nqubits,singles,biases,pairs,couplings)
    print(h0)


.. parsed-literal::

    (0.4+0j)*Z0*Z1 + (0.6+0j)*Z1*Z2 + (0.3+0j)*Z1


Random Hamiltonian
^^^^^^^^^^^^^^^^^^

The ``.random_hamiltonian()`` method allows us to generate a random
Hamiltonian (problem instance) for a specified number of qubits. It
randomly selects a number of biases and number of couplings, then
assigns each of them a random value between zero and one. For instance,
let’s create two 4-qubit Hamiltonians.

.. code:: ipython3

    h1 = random_hamiltonian(range(4))
    h2 = random_hamiltonian(range(4))
    print("h1 =",h1)
    print()
    print("h2 =",h2)


.. parsed-literal::

    h1 = (0.004900348867947435+0j)*Z3 + (0.21901286736897008+0j)*Z0 + (0.15051036418505226+0j)*Z0*Z1 + (0.1676281685151534+0j)*Z0*Z2 + (0.13006962415006895+0j)*Z0*Z3 + (0.5410897163886795+0j)*Z1*Z2 + (0.9327111643297196+0j)*Z2*Z3
    
    h2 = (0.34593388397329305+0j)*Z0 + (0.8360959486271519+0j)*Z0*Z2 + (0.11829423825238738+0j)*Z0*Z3


Hamiltonians to Graphs
^^^^^^^^^^^^^^^^^^^^^^

We can create a ``NetworkX`` graph corresponding to the qubit couplings
in ``h1`` using the ``graph_from_hamiltonian`` method and then plot it
using ``plot_graph()``:

.. code:: ipython3

    g1 = graph_from_hamiltonian(h1)
    plot_graph(g1)



.. image:: 5_QAOAUtilities_files/5_QAOAUtilities_9_0.png


Graphs to Hamiltonians
^^^^^^^^^^^^^^^^^^^^^^

Alternatively, we can work backwards, creating a graph first, then the
corresponding Hamiltonian using the ``hamiltonian_from_graph()`` method.

Let’s take the graph we have just produced (``g1``) and convert it back
to its corresponding Hamiltonian, which we called ``h1`` above.

.. code:: ipython3

    H1 = hamiltonian_from_graph(g1)
    print('From graph:', H1)
    print('')
    print('Original:', h1)


.. parsed-literal::

    From graph: (0.004900348867947435+0j)*Z3 + (0.21901286736897008+0j)*Z0 + (0.13006962415006895+0j)*Z3*Z0 + (0.9327111643297196+0j)*Z3*Z2 + (0.15051036418505226+0j)*Z0*Z1 + (0.1676281685151534+0j)*Z0*Z2 + (0.5410897163886795+0j)*Z1*Z2
    
    Original: (0.004900348867947435+0j)*Z3 + (0.21901286736897008+0j)*Z0 + (0.15051036418505226+0j)*Z0*Z1 + (0.1676281685151534+0j)*Z0*Z2 + (0.13006962415006895+0j)*Z0*Z3 + (0.5410897163886795+0j)*Z1*Z2 + (0.9327111643297196+0j)*Z2*Z3


Hyperparameters to Graphs
^^^^^^^^^^^^^^^^^^^^^^^^^

We can also create a graph directly from hyperparameters, using the
``graph_from_hyperparams()`` method. Here we use the Hamiltonian created
`above <#hyperparams_to_ham>`__.

.. code:: ipython3

    g0 = graph_from_hyperparams(nqubits, singles, biases, pairs, couplings)
    plot_graph(g0)



.. image:: 5_QAOAUtilities_files/5_QAOAUtilities_13_0.png


Random, regular Graphs
^^^^^^^^^^^^^^^^^^^^^^

In recent research on QAOA, there has been interest in the performance
of the algorithm on :math:`k`-regular graphs, i.e. graphs where every
node is connected to exactly :math:`k` other nodes. We can generate such
graphs easily using the ``random_k_regular_graph()`` function. For
instance, let’s create a 3-regular graph with 8 nodes:

.. code:: ipython3

    G_3_reg = random_k_regular_graph(3, range(8), weighted=True)
    plot_graph(G_3_reg)



.. image:: 5_QAOAUtilities_files/5_QAOAUtilities_15_0.png


Hamiltonians and data
---------------------

One prominent application of QAOA is to solve the weighted MaxCut
problem, which may be used as a clustering technique - see, for example,
`Ref 1 <#references>`__. Here, the pairwise distance between a given
pair of data points in a dataset is used as the weight on the
corresponding graph, and enters the Hamiltonian as the corresponding
coupling coefficient between the corresponding qubits.

In the following, we demo some steps of a workflow to use QAOA to solve
such a MaxCut problem for clustering. We use simple toy data generated
by the ``gaussian_2Dclusters()`` function.

Cluster generation and distance calculations
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Let’s create a data set of two clusters, where the points in each
cluster follow Gaussian statistics.

.. code:: ipython3

    n_clusters = 2 # Number of clusters we want 
    n_points = [3,3] # Number of data points in each cluster
    means = [[0,0], [2,2]] # Cluster means (the [x,y] coordinates of each cluster centre)
    
    # Covariance matrix: we will use the same one for each of the two clusters here,
    # but more generally they could be different
    cov_matrix = [[0.1, 0], [0, 0.1]] 
    cov_matrices = [cov_matrix,cov_matrix]
    
    cluster_data = gaussian_2Dclusters(n_clusters,n_points,means,cov_matrices)
    plot_cluster_data(cluster_data)



.. image:: 5_QAOAUtilities_files/5_QAOAUtilities_18_0.png


The next step in setting up the MaxCut problem is to compute the
pairwise distances of the points in the dataset, which we can do using
the ``distances_dataset()`` function. Here we will use the Euclidean
distance, but more generally we can ask for any distance metric included
in Scipy’s
`cdist <https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html>`__
function.

.. code:: ipython3

    dists = distances_dataset(cluster_data, metric='euclidean')
    dists




.. parsed-literal::

    array([[0.        , 0.82897286, 0.25412122, 2.7208397 , 2.4882139 ,
            2.696585  ],
           [0.82897286, 0.        , 0.69353841, 2.7068499 , 2.38417206,
            2.80707853],
           [0.25412122, 0.69353841, 0.        , 2.50460246, 2.25679993,
            2.50414529],
           [2.7208397 , 2.7068499 , 2.50460246, 0.        , 0.39691127,
            0.41284593],
           [2.4882139 , 2.38417206, 2.25679993, 0.39691127, 0.        ,
            0.74243907],
           [2.696585  , 2.80707853, 2.50414529, 0.41284593, 0.74243907,
            0.        ]])



Note that ``distances_dataset()`` can also take and return data in the
Pandas dataframe format.

Distance datasets to Hamiltonians
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Now that we have the distances between all points in the dataset, we
want to generate the corresponding MaxCut Hamiltonian. We can do this
easily with the ``hamiltonian_from_distances()`` method.

.. code:: ipython3

    hData = hamiltonian_from_distances(dists)
    print(hData)


.. parsed-literal::

    (0.8289728598343151+0j)*Z0*Z1 + (0.25412121547104277+0j)*Z0*Z2 + (2.7208397046549373+0j)*Z0*Z3 + (2.488213904805076+0j)*Z0*Z4 + (2.696584998506985+0j)*Z0*Z5 + (0.6935384144076524+0j)*Z1*Z2 + (2.7068499027612867+0j)*Z1*Z3 + (2.384172061944766+0j)*Z1*Z4 + (2.807078534694894+0j)*Z1*Z5 + (2.504602455697225+0j)*Z2*Z3 + (2.256799930531896+0j)*Z2*Z4 + (2.504145288140382+0j)*Z2*Z5 + (0.3969112729568394+0j)*Z3*Z4 + (0.412845933315702+0j)*Z3*Z5 + (0.7424390665987094+0j)*Z4*Z5


For simplicity here we have omitted terms proportional to the identity
matrix, which are commonly included in the definition of the MaxCut cost
function. Since such terms only introduce a global energy shift, they do
not affect the optimal configuration that we find as a solution.

Example 1: Using QAOA to solve MaxCut for the clustering problem
----------------------------------------------------------------

Now that we have the Hamiltonian, we can go ahead and run the QAOA to
check that the points are clustered correctly. We will use the
``ExtendedParams`` class, and three timesteps (p=3). We don’t include
any single-qubit bias terms.

.. code:: ipython3

    n_qubits = 6
    p = 3
    
    # Specify some angles
    betas = np.random.rand(n_qubits,p)
    gammas_singles = []
    gammas_pairs = np.random.rand(len(hData),p)
    parameters = (betas,gammas_singles,gammas_pairs)
    
    extended_params = ExtendedParams([hData,p],parameters)
    
    # NOTE - the optimiser will reach its maximum number of iterations, but for the parameters being used here,
    # the choice maxiter=200 seems to be more than sufficient to get to the optimum with high probability.
    cost_function = QAOACostFunctionOnWFSim(hData,
                                            params=extended_params,
                                            scalar_cost_function=False)
    
    res = minimize(cost_function, extended_params.raw(),
                   tol=1e-3, method="Cobyla", options={"maxiter": 200})
    res




.. parsed-literal::

         fun: -10.810294983486513
       maxcv: 0.0
     message: 'Maximum number of function evaluations has been exceeded.'
        nfev: 200
      status: 2
     success: False
           x: array([ 0.32837978,  0.97855922,  1.79667302,  1.55509154,  0.66696867,
            0.87951054,  0.95179681,  0.61356477,  0.9858554 ,  0.44337656,
            0.37776991,  0.9992281 ,  1.59461262,  0.73024521,  0.73375343,
            0.34736038,  0.87027853,  0.65597584,  0.89448078,  2.31121969,
            1.68453049,  0.10603794,  0.93558084,  0.15552382,  1.62178437,
            0.62497075,  0.1217987 ,  0.77176759,  0.8899081 ,  0.71719219,
            0.88906001, -0.30232524,  0.42328429,  0.51251464,  0.31569421,
            0.15417377,  0.82953154,  0.01492303,  1.85023048,  0.75447022,
            0.3913274 ,  0.76209187,  0.81826248,  1.53127724,  0.63301349,
            0.92862761,  0.64108281,  0.11464491,  0.22439417,  0.36908476,
            1.98726247,  0.67616129,  1.55324709,  0.14175055,  0.17962969,
            0.3617202 ,  1.63780497,  1.47016926,  0.18769132,  0.77039777,
            0.35670891,  0.18458257,  0.66690106])



Let us plot the probabilities of the different bitstrings. Since the
energies are invariant under a bit flip on all qubits, each bitstring
and its complement have identical outcome probabilities.

.. code:: ipython3

    opt_wfn = cost_function.get_wavefunction(res.x)
    probs = opt_wfn.probabilities()
    plt.bar(range(len(probs)), probs)
    plt.show()



.. image:: 5_QAOAUtilities_files/5_QAOAUtilities_28_0.png


Now we want to find the string corresponding to the optimal solution.
Numpy’s ``argmax`` function will return the first of the two degenerate
solutions. As expected, we find that the first three qubits are in one
class, and the second three qubits in another (this is the way the data
was constructed above, in two distinct clusters).

.. code:: ipython3

    optimal_string = np.argmax(probs)
    "{0:06b}".format(optimal_string)




.. parsed-literal::

    '000111'



We can check that the other optimal solution found is the complement
bitstring, i.e. 111000:

.. code:: ipython3

    probs[optimal_string] = 0 # Sets the solution 000111 to have zero probability
    optimal_string_complement = np.argmax(probs)
    "{0:06b}".format(optimal_string_complement)




.. parsed-literal::

    '111000'



Example 2: The Ring of Disagrees
--------------------------------

The *Ring of Diasgrees* is a 2-regular graph on a given number of nodes
:math:`n`. Its simple structure has allowed a number of extremely useful
benchmarking results for QAOA to be derived. The ground state has energy
:math:`-n` for even :math:`n`, and :math:`-n+1` for odd :math:`n`, and
neighbouring nodes have opposite values (i.e. if a given node has value
1, its neighbour has value 0).

In the paper that originally introduced the QAOA (`Ref
2 <#references>`__), it was shown numerically that this graph provides a
simple example of how the approximation ratio returned by QAOA can be
made arbitrarily close to 1 by increasing the parameter :math:`p`. For
the MaxCut problem, the optimal cost function value returned for a given
:math:`n` and :math:`p` was found to be

.. math::


   C(n,p) = \left(\frac{2p + 1}{2p + 2}\right)n

This result assumes the ``StandardParams`` parameterisation, and that
the graph is unweighted (all edge weights equal to 1). Here we verify
this result using the ``ring_of_disagrees()`` function. Note that
subsequent to `Ref 2 <#references>`__, this result has been derived
using analytic methods in `Ref 3 <#references>`__.

.. code:: ipython3

    n_nodes = 8
    h_disagrees = ring_of_disagrees(n_nodes)
    g_disagrees = graph_from_hamiltonian(h_disagrees)
    plot_graph(g_disagrees)



.. image:: 5_QAOAUtilities_files/5_QAOAUtilities_34_0.png


.. code:: ipython3

    def optimise_ring_of_disagrees(pval):
        
        # Initialise angles
        betas = np.random.rand(pval)
        gammas = np.random.rand(pval)
        parameters = (betas, gammas)
    
        # Set up (hyper)parameters
        disagrees_params = StandardParams([h_disagrees,pval],parameters)
        
        # Cost function and optimisation
        cost_function = QAOACostFunctionOnWFSim(h_disagrees, params=disagrees_params)
        
        res = minimize(cost_function, disagrees_params.raw(),
                       tol=1e-3, method="BFGS", options={"maxiter": 500})
        
        return res.fun, res.x
        
    
    p_vals = np.arange(1,5) # p range to consider
    output_val = np.zeros((len(p_vals),))
    for i in p_vals:
    
        output_val[i-1] = optimise_ring_of_disagrees(i)[0]

Since we have 8 qubits, according to Farhi’s formula we should find the
maximum energy to be
:math:`-8 \cdot (3/4,5/6,7/8,9/10) = -(6, 6.67, 7, 7.2)` for
:math:`p = (1,2,3,4)`:

.. code:: ipython3

    output_val




.. parsed-literal::

    array([-6.        , -6.66666666, -7.        , -7.99999998])



For the case :math:`p=1`, the optimal angles can be computed
analytically, and are given by
:math:`(\beta_{opt}, \gamma_{opt}) = (\pi/8, \pi/4`) - see `Ref
4 <#references>`__. We can see that the optimiser does indeed return
these angles:

.. code:: ipython3

    opt_angles = optimise_ring_of_disagrees(1)[1]
    opt_angles




.. parsed-literal::

    array([0.39269965, 0.78539607])



Let’s finish off by running an example of the Ring of Disagrees on the
QVM; we would follow a similar method to run the computation on the QPU.
We’ll use the optimal angles we have just found to check that the
probability distribution of samples we obtain does indeed return the
bitstring [0,1,0,1], or its complement [1,0,1,0], with high probability.

Here, we make use of the ``sample_bitstrings`` function, which executes
the circuit defined by the QAOA instance and samples from output
multiple times. We can plot the output conveniently using
``bitstring_histogram``.

.. code:: ipython3

    from pyquil.api import get_qc
    from entropica_qaoa.qaoa.cost_function import QAOACostFunctionOnQVM
    from entropica_qaoa.utilities import bitstring_histogram
    
    qvm = get_qc("4q-qvm")
    
    ham_disagrees_4 = ring_of_disagrees(4)
    params_disagrees_4 = StandardParams([ham_disagrees_4,1], opt_angles)
    cost_fn_disagrees_4 = QAOACostFunctionOnQVM(ham_disagrees_4, params=params_disagrees_4, qvm=qvm)
    
    bitstrings = cost_fn_disagrees_4.sample_bitstrings()
    bitstring_histogram(bitstrings)



.. image:: 5_QAOAUtilities_files/5_QAOAUtilities_41_0.png


More miscellaneous utilities
----------------------------

Here we demonstrate the functionality of some additional methods that
may be useful in certain contexts.

Different initial states for QAOA
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We can easily use an initial state different from
:math:`\left|+ \cdots +\right>` for QAOA, by passing a state preparation
program for the ``initial_state`` argument of the QAOA cost functions.
For purely classical states (i.e. not a quantum superposition state)
such as :math:`\left|10 \cdots 10\right>`, these programs cane be
created via ``prepare_classical_state``.

.. code:: ipython3

    register = [0, 1, 2, 3, 4, 5]  # the register to create the state on
    state = [1, 0, 1, 0, 1, 0]     # the |42> state (encodes the decimal number 42)
    
    prepare42_circuit = prepare_classical_state(register, state)
    print(prepare42_circuit)


.. parsed-literal::

    X 0
    X 2
    X 4
    


Get the bitstring corresponding to the maximum probability state
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The ``max_probability_bitstring()`` method returns the bitstring
corresponding to the maximum probability state of a wavefunction.

.. code:: ipython3

    probs = np.exp(-np.linspace(-5, 10, 16)**2) # just an array of length 16 (corresponds to a 4-qubit system)
    probs = probs/probs.sum() # normalise to represent a proper probability distribution
    max_prob_state = max_probability_bitstring(probs)
    print(max_prob_state)


.. parsed-literal::

    [0, 1, 0, 1]


Accuracy scores for QAOA
^^^^^^^^^^^^^^^^^^^^^^^^

``cluster_accuracy()`` gives accuary scores for a QAOA result, if the
true solution is known. The accuracy here is defined as the percentage
of bits that are correct compared to the known solution.

.. code:: ipython3

    cluster_accuracy(max_prob_state, true_labels=[1, 1, 0, 0])


.. parsed-literal::

    True Labels of samples: [1, 1, 0, 0]
    Lowest QAOA State: [0, 1, 0, 1]
    Accuracy of Original State: 50.0 %
    Accuracy of Complement State: 50.0 %


Get nice plots of probabilties
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

If the true energies of all states are known, we can also obtain a nice
side-by-side plot of the energies and probabilites using
``plot_probabilities()``.

.. code:: ipython3

    energies = np.sin(np.linspace(0, 10, 16))
    fig, ax = plt.subplots(figsize=(10,5))
    plot_probabilities(probs, energies, ax=ax)



.. image:: 5_QAOAUtilities_files/5_QAOAUtilities_50_0.png


References
----------

1. J. S. Otterbach et al, `Unsupervised Machine Learning on a Hybrid
   Quantum Computer <https://arxiv.org/abs/1712.05771>`__
2. E. Farhi et al, `A Quantum Approximate Optimization
   Algorithm <https://arxiv.org/abs/1411.4028>`__
3. Z. Wang et al, `The Quantum Approximation Optimization Algorithm for
   MaxCut: A FermionicView <https://arxiv.org/pdf/1706.02998.pdf>`__
4. S. Hadfield, `Quantum Algorithms for Scientific Computing
   andApproximate Optimization <https://arxiv.org/pdf/1805.03265.pdf>`__
