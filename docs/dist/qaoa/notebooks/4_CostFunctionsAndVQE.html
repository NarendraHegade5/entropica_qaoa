

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Cost function features and VQE &mdash; Entropica QAOA  documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Utility functions for QAOA" href="5_QAOAUtilities.html" />
    <link rel="prev" title="Advanced QAOA parameter classes" href="3_AdvancedParameterClasses.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Entropica QAOA
          

          
            
            <img src="../_static/ELlogo_small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../tutorials_overview.html">Overview of tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_AnExampleWorkflow.html">First steps: An example workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_ParameterClasses.html">Working with the Parameter classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_AdvancedParameterClasses.html">Advanced QAOA parameter classes</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Cost function features and VQE</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#short-intro-the-variational-quantum-eigensolver-vqe">Short Intro: The Variational Quantum Eigensolver (VQE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#setting-up-the-problem">Setting up the problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="#simulating-sampling-noise">Simulating sampling noise</a></li>
<li class="toctree-l2"><a class="reference internal" href="#getting-the-measurement-variance">Getting the measurement variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="#logging-of-the-optimisation-process">Logging of the optimisation process</a></li>
<li class="toctree-l2"><a class="reference internal" href="#running-on-the-qvm-or-qpu">Running on the QVM or QPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-other-optimisers">Using other optimisers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#towards-qaoa">Towards QAOA</a></li>
<li class="toctree-l2"><a class="reference internal" href="#appendix-simulated-measurement-noise-statistics-implementation-details">Appendix: Simulated measurement noise - statistics implementation details</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="5_QAOAUtilities.html">Utility functions for QAOA</a></li>
<li class="toctree-l1"><a class="reference internal" href="6_ClusteringWithQAOA.html">Solve the clustering problem using QAOA</a></li>
</ul>
<p class="caption"><span class="caption-text">General Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Implementation details and conventions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
</ul>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vqe_cost_function.html">VQE cost functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../qaoa_cost_function.html">QAOA cost functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parameters.html">QAOA Parametrisations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utilities.html">VQE and QAOA utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../measurelib.html">Measurement utilities</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Entropica QAOA</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Cost function features and VQE</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notebooks/4_CostFunctionsAndVQE.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="cost-function-features-and-vqe">
<span id="costfunctionsandvqe"></span><h1>Cost function features and VQE<a class="headerlink" href="#cost-function-features-and-vqe" title="Permalink to this headline">¶</a></h1>
<p>This notebook showcases the more advanced features of our cost functions
using the example of VQE. Since QAOA can be thought of as a special case
of VQE, everything said here applies also to the QAOA cost functions,
unless otherwise explicitly mentioned.</p>
<p>As with all the Demo Notebooks, you need to start the Simulator and the
Quil Compiler in the background by typing <code class="docutils literal notranslate"><span class="pre">qvm</span> <span class="pre">-S</span></code> and <code class="docutils literal notranslate"><span class="pre">quilc</span> <span class="pre">-S</span></code> in
two open and disposable terminal windows.</p>
<div class="section" id="short-intro-the-variational-quantum-eigensolver-vqe">
<h2>Short Intro: The Variational Quantum Eigensolver (VQE)<a class="headerlink" href="#short-intro-the-variational-quantum-eigensolver-vqe" title="Permalink to this headline">¶</a></h2>
<p>We begin with a short introduction to the VQE to establish nomenclature.
The aim of VQE is to find the ground state and/or ground state energy of
a given cost hamiltonian <span class="math notranslate nohighlight">\(\hat{H}_\mathrm{cost}\)</span>. To do so, one
prepares a trial state
<span class="math notranslate nohighlight">\(\left| \psi (\vec{\gamma})\right&gt; = \hat{U}(\vec{\gamma}) \left| 0 \right&gt;\)</span>
by applying a parametric program <span class="math notranslate nohighlight">\(\hat{U}(\vec{\gamma})\)</span> to the
initial state <span class="math notranslate nohighlight">\(\left| 0 \right&gt;\)</span>, and then measures its energy
expectation value with respect to the cost Hamiltonian,
<span class="math notranslate nohighlight">\(\left&lt;\hat{H}_\mathrm{cost}\right&gt;(\vec{\gamma}) = \left&lt; \psi(\vec{\gamma}) \right|\hat{H}\left| \psi(\vec{\gamma})\right&gt;\)</span>.
This expectation value is then minimized by optimizing the parameters
<span class="math notranslate nohighlight">\(\vec{\gamma}\)</span> in a classical optimizer until a minimum of
<span class="math notranslate nohighlight">\(\left&lt;\hat{H}_\mathrm{cost}\right&gt;(\vec{\gamma})\)</span> is found for a
parameter set <span class="math notranslate nohighlight">\(\vec{\gamma}^*\)</span>. The lowest energy eigenstate of
<span class="math notranslate nohighlight">\(\hat{H_\mathrm{cost}}\)</span> can now be prepared by applying
<span class="math notranslate nohighlight">\(\hat{U}(\vec{\gamma}^*)\)</span> to <span class="math notranslate nohighlight">\(\left| 0 \right&gt;\)</span>, and its
energy is given by
<span class="math notranslate nohighlight">\(E_0 = \left&lt; \psi(\vec{\gamma}^*) \right|\hat{H}_\mathrm{cost}\left| \psi(\vec{\gamma}^*)\right&gt;\)</span></p>
<p>Now it should also be clear, that QAOA can be considered as a special
case of VQE where the Ansatz is fixed to be of the form</p>
<div class="math notranslate nohighlight">
\[\hat{U}(\vec{\beta}, \vec{\gamma})
    = e^{-i \beta_p H_M} e^{-i \gamma_p H_C}
      \cdots
      e^{-i \beta_0 H_M} e^{-i \gamma_1 H_C}\]</div>
<p>with the free parameters <span class="math notranslate nohighlight">\(\vec{\beta}, \vec{\gamma}\)</span>.</p>
<p>Before we begin, let us first import all neccesary libraries:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The usual combination of scipy, numpy and matplotlib</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c1"># The pyquil dependencies</span>
<span class="kn">from</span> <span class="nn">pyquil.paulis</span> <span class="kn">import</span> <span class="n">PauliSum</span><span class="p">,</span> <span class="n">PauliTerm</span>
<span class="kn">from</span> <span class="nn">pyquil.api</span> <span class="kn">import</span> <span class="n">WavefunctionSimulator</span><span class="p">,</span> <span class="n">get_qc</span>
<span class="kn">from</span> <span class="nn">pyquil.quil</span> <span class="kn">import</span> <span class="n">Program</span>
<span class="kn">from</span> <span class="nn">pyquil.gates</span> <span class="kn">import</span> <span class="n">RY</span><span class="p">,</span> <span class="n">H</span>
<span class="kn">from</span> <span class="nn">pyquil.unitary_tools</span> <span class="kn">import</span> <span class="n">lifted_pauli</span>

<span class="c1"># A finally the cost functions</span>
<span class="kn">from</span> <span class="nn">entropica_qaoa.vqe.cost_function</span> <span class="kn">import</span> <span class="p">(</span><span class="n">PrepareAndMeasureOnWFSim</span><span class="p">,</span>
                                              <span class="n">PrepareAndMeasureOnQVM</span><span class="p">,</span>
                                              <span class="n">pauli_matrix</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">entropica_qaoa.qaoa.cost_function</span> <span class="kn">import</span> <span class="n">QAOACostFunctionOnWFSim</span>

<span class="c1"># And one our QAOA parameter classes</span>
<span class="kn">from</span> <span class="nn">entropica_qaoa.qaoa.parameters</span> <span class="kn">import</span> <span class="n">StandardParams</span><span class="p">,</span> <span class="n">FourierParams</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="setting-up-the-problem">
<h2>Setting up the problem<a class="headerlink" href="#setting-up-the-problem" title="Permalink to this headline">¶</a></h2>
<p>We start by creating a cost hamiltonian <code class="docutils literal notranslate"><span class="pre">hamiltonian</span></code> and state
preparation program <code class="docutils literal notranslate"><span class="pre">prepare_ansatz</span></code>. For demonstration purposes we
will use the simplest possible problem for VQE: the hamiltonian is the
bit-flip operator <span class="math notranslate nohighlight">\(X\)</span> (Pauli operator <span class="math notranslate nohighlight">\(\sigma_X\)</span>) on a
single qubit, and the parametric program consists of a single
<span class="math notranslate nohighlight">\(R_y\)</span>-rotation. The parameter <span class="math notranslate nohighlight">\(\gamma\)</span> is the rotation angle
of this rotation.</p>
<p><strong>Note</strong></p>
<p>Besides an <code class="docutils literal notranslate"><span class="pre">RY</span></code> gate, we also need to add a <code class="docutils literal notranslate"><span class="pre">declare</span></code> instruction to
<code class="docutils literal notranslate"><span class="pre">prepare_ansatz</span></code> to declare a classical memory register. Later the
rotation angle <code class="docutils literal notranslate"><span class="pre">gamma</span></code> will be written (by the user/optimiser) and
read (by the WavefunctionSimulaor/QVM) from this register. This design
allows our VQE and QAOA cost functions to make use of Quil’s <a class="reference external" href="http://docs.rigetti.com/en/latest/basics.html?programs#parametric-compilation">parametric
compilation</a>,
and we don’t have to recompile the program every time we update the
parameters.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create the cost hamiltonian</span>
<span class="n">hamiltonian</span> <span class="o">=</span> <span class="n">PauliSum</span><span class="p">([</span><span class="n">PauliTerm</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)])</span>

<span class="c1"># and the parametric state preparation program:</span>
<span class="n">prepare_ansatz</span> <span class="o">=</span> <span class="n">Program</span><span class="p">()</span> <span class="c1"># builds an empty program</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">prepare_ansatz</span><span class="o">.</span><span class="n">declare</span><span class="p">(</span><span class="s2">&quot;params&quot;</span><span class="p">,</span> <span class="c1"># add a classical register to store the values in</span>
                                <span class="n">memory_type</span><span class="o">=</span><span class="s2">&quot;REAL&quot;</span><span class="p">,</span> <span class="n">memory_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">#prepare_ansatz.inst(H(0))</span>
<span class="n">prepare_ansatz</span><span class="o">.</span><span class="n">inst</span><span class="p">(</span><span class="n">RY</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The hamiltonian</span><span class="se">\n</span><span class="s2">&quot;</span>
      <span class="s2">&quot;---------------</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">hamiltonian</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">The program</span><span class="se">\n</span><span class="s2">&quot;</span>
      <span class="s2">&quot;-----------</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">prepare_ansatz</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">hamiltonian</span>
<span class="o">---------------</span>
 <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="mi">0</span><span class="n">j</span><span class="p">)</span><span class="o">*</span><span class="n">X0</span>

<span class="n">The</span> <span class="n">program</span>
<span class="o">-----------</span>
 <span class="n">DECLARE</span> <span class="n">params</span> <span class="n">REAL</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">RY</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="mi">0</span>
</pre></div>
</div>
<p>Next we can create a cost function to be passed to a classical optimizer
later. We do this using <code class="docutils literal notranslate"><span class="pre">vqe.cost_function.PrepareAndMeasureOnWFSim</span></code>,
a class that combines a cost hamiltonian <code class="docutils literal notranslate"><span class="pre">hamiltonian</span></code> and a state
preparation circuit <code class="docutils literal notranslate"><span class="pre">prepare_ansatz</span></code>. This cost function can
subsequently be passed to any classical optimizer - here we will use
methods available in <code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimize</span></code>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create the cost_function with our ansatz and hamiltonian:</span>
<span class="n">cost_fun</span> <span class="o">=</span> <span class="n">PrepareAndMeasureOnWFSim</span><span class="p">(</span><span class="n">prepare_ansatz</span><span class="o">=</span><span class="n">prepare_ansatz</span><span class="p">,</span>
                                    <span class="n">make_memory_map</span><span class="o">=</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">p</span><span class="p">},</span>
                                    <span class="n">hamiltonian</span><span class="o">=</span><span class="n">hamiltonian</span><span class="p">)</span>
</pre></div>
</div>
<p>With the cost function set up, let us have a look at it graphically:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gammas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span>
<span class="n">exp_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">gammas</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gammas</span><span class="p">):</span>
    <span class="n">exp_vals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">cost_fun</span><span class="p">([</span><span class="n">v</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gammas</span><span class="p">,</span> <span class="n">exp_vals</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\gamma$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost function&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/4_CostFunctionsAndVQE_11_0.png" src="../_images/4_CostFunctionsAndVQE_11_0.png" />
<p>We can also find the minimal function value and argument:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># the initial argument</span>
<span class="n">gamma0</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># and minimization</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">cost_fun</span><span class="p">,</span> <span class="n">gamma0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;Cobyla&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="n">fun</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.9999999954355244</span>
  <span class="n">maxcv</span><span class="p">:</span> <span class="mf">0.0</span>
<span class="n">message</span><span class="p">:</span> <span class="s1">&#39;Optimization terminated successfully.&#39;</span>
   <span class="n">nfev</span><span class="p">:</span> <span class="mi">24</span>
 <span class="n">status</span><span class="p">:</span> <span class="mi">1</span>
<span class="n">success</span><span class="p">:</span> <span class="kc">True</span>
      <span class="n">x</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.57070078</span><span class="p">])</span>
</pre></div>
</div>
<p><strong>Aside: Interpretation for the interested reader</strong></p>
<p>The plot above can be interpreted as follows. The qubit starts in the
state <span class="math notranslate nohighlight">\(|0\rangle\)</span>, and the operator <span class="math notranslate nohighlight">\(RY(\gamma)\)</span> rotates its
Bloch vector about the Y-axis through an angle <span class="math notranslate nohighlight">\(\gamma\)</span>. For
<span class="math notranslate nohighlight">\(\gamma = 0\)</span> the qubit remains in <span class="math notranslate nohighlight">\(|0\rangle\)</span>, which is an
eigenstate of the Pauli <span class="math notranslate nohighlight">\(Z\)</span> operator, and therefore the
expectation value of the cost function <span class="math notranslate nohighlight">\(X\)</span> is zero. For
<span class="math notranslate nohighlight">\(\gamma = \pm\pi\)</span>, we flip the qubit to the state
<span class="math notranslate nohighlight">\(|1\rangle\)</span>, which is again an eigenstate of the <span class="math notranslate nohighlight">\(Z\)</span>
operator, and thus has zero expectation value in the <span class="math notranslate nohighlight">\(x\)</span>-basis.
When <span class="math notranslate nohighlight">\(\gamma = \pm \pi/2\)</span>, we create the superposition states
<span class="math notranslate nohighlight">\(|\pm\rangle = (|0\rangle \pm |1\rangle)/\sqrt{2}\)</span>, which are
eigenstates of the <span class="math notranslate nohighlight">\(X\)</span> operator, and we therefore find the maximum
and minimum values of the cost function, <span class="math notranslate nohighlight">\(\pm 1\)</span>.</p>
<p>The result <code class="docutils literal notranslate"><span class="pre">out</span></code> should now contain the minimal eigenvalue of
<code class="docutils literal notranslate"><span class="pre">hamiltonian</span></code> as the minimum function value, and the correct
parameters for <code class="docutils literal notranslate"><span class="pre">prepare_ansatz</span></code> to prepare the corresponding
eigenstate. We can compare this with the real minimum eigenvalue, by
printing <code class="docutils literal notranslate"><span class="pre">hamiltonian</span></code> as a matrix:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;The output of scipy.optimize.minimize:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">out</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> And the eigenvalues of the hamiltonian:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvalsh</span><span class="p">(</span><span class="n">pauli_matrix</span><span class="p">(</span><span class="n">hamiltonian</span><span class="p">)))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">output</span> <span class="n">of</span> <span class="n">scipy</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">:</span>
      <span class="n">fun</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.9999999954355244</span>
   <span class="n">maxcv</span><span class="p">:</span> <span class="mf">0.0</span>
 <span class="n">message</span><span class="p">:</span> <span class="s1">&#39;Optimization terminated successfully.&#39;</span>
    <span class="n">nfev</span><span class="p">:</span> <span class="mi">24</span>
  <span class="n">status</span><span class="p">:</span> <span class="mi">1</span>
 <span class="n">success</span><span class="p">:</span> <span class="kc">True</span>
       <span class="n">x</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.57070078</span><span class="p">])</span>

 <span class="n">And</span> <span class="n">the</span> <span class="n">eigenvalues</span> <span class="n">of</span> <span class="n">the</span> <span class="n">hamiltonian</span><span class="p">:</span>
 <span class="p">[</span><span class="o">-</span><span class="mf">1.</span>  <span class="mf">1.</span><span class="p">]</span>
</pre></div>
</div>
<p>This looks good - it seems we found the ground state almost exactly. On
a real quantum computer, however, we can’t measure the expectation value
of a state directly. Instead, we have to take multiple samples, and
calculate the mean of the resulting output values. The more samples we
take from the output state, the closer the sample mean of the ground
state energy will come to its true mean. We can think of the effect of
taking only a finite number of samples as adding uncertainty, or noise,
to the true underlying probability distribution.</p>
<p>In practice, if we have only an estimate of the energy, but not its true
value, this will influence the effectiveness of different optimisers.
Gradient-based optimisers, for example, work well when we have exact
function values, and we can compute gradients through finite differences
to determine where to move in the next iteration. In the presence of
noisy function value estimates, we may expect such methods to be less
effective.</p>
<p>To effciently simulate the effect of this sampling noise, the
<code class="docutils literal notranslate"><span class="pre">PrepareAndMeasureOnWFSim</span></code> has an argument <code class="docutils literal notranslate"><span class="pre">nshots</span></code> that we will
demonstrate in the following section.</p>
</div>
<div class="section" id="simulating-sampling-noise">
<h2>Simulating sampling noise<a class="headerlink" href="#simulating-sampling-noise" title="Permalink to this headline">¶</a></h2>
<p>To see how this sampling noise influences the behaviour of different
optimisers, we provide the <code class="docutils literal notranslate"><span class="pre">nshots</span></code> option in the Wavefunction
Simulator cost function <code class="docutils literal notranslate"><span class="pre">PrepareAndMeasureOnWFSim</span></code>. If we set
<code class="docutils literal notranslate"><span class="pre">nshots=N</span></code> in either the cost function constructor or the cost
function call, it will return the true expectation value plus simulated
sampling noise with the (approximate) statistics of the true noise at
<span class="math notranslate nohighlight">\(N\)</span> samples. Note the word “approximate” here: to speed up
simulations, we use a Gaussian approximation of the noise, instead of
actually taking <span class="math notranslate nohighlight">\(N\)</span> samples. This works very well for large
<span class="math notranslate nohighlight">\(N\)</span> (where it also gives the largest speed up), but can lead to
unphysical results for small <span class="math notranslate nohighlight">\(N\)</span>, such as expectation values lower
than the actual minimum expectation value. More details on the
implementation of this simulated sampling noise are given in the last
section <a class="reference external" href="#statistics_details">below</a>.</p>
<p>[For clarity, note that if we are using the QVM or QPU and corresponding
cost function <code class="docutils literal notranslate"><span class="pre">PrepareAndMeasureOnQVM</span></code>, the argument <code class="docutils literal notranslate"><span class="pre">nshots</span></code> is
compulsory, and the noise is not mimicked using the Gaussian
approximation - it is the true noise obtained by taking the specified
finite number of samples.]</p>
<p>Let us now create a cost function that adds the simulated sampling noise
for <span class="math notranslate nohighlight">\(N=1000\)</span> shots, and also <span class="math notranslate nohighlight">\(N = 5\)</span> shots.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create the cost_function with our ansatz and hamiltonian:</span>
<span class="n">cost_fun</span> <span class="o">=</span> <span class="n">PrepareAndMeasureOnWFSim</span><span class="p">(</span><span class="n">prepare_ansatz</span><span class="o">=</span><span class="n">prepare_ansatz</span><span class="p">,</span>
                                    <span class="n">make_memory_map</span><span class="o">=</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">p</span><span class="p">},</span>
                                    <span class="n">hamiltonian</span><span class="o">=</span><span class="n">hamiltonian</span><span class="p">,</span>
                                    <span class="n">nshots</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gammas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span>
<span class="n">exp_vals1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">gammas</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gammas</span><span class="p">):</span>
    <span class="n">exp_vals1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">cost_fun</span><span class="p">([</span><span class="n">v</span><span class="p">])</span>

<span class="n">exp_vals2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">gammas</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gammas</span><span class="p">):</span>
    <span class="n">exp_vals2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">cost_fun</span><span class="p">([</span><span class="n">v</span><span class="p">],</span> <span class="n">nshots</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># Note: by passing in nshots here, we override the value of 1000</span>
                                           <span class="c1"># from above</span>
</pre></div>
</div>
<p>Now plot the outcomes side by side:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gammas</span><span class="p">,</span> <span class="n">exp_vals2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;cost function&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;nshots=5&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\gamma$&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gammas</span><span class="p">,</span> <span class="n">exp_vals1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;cost function&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\gamma$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;nshots=1000&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/4_CostFunctionsAndVQE_22_0.png" src="../_images/4_CostFunctionsAndVQE_22_0.png" />
<p>In the left panel we see that when <code class="docutils literal notranslate"><span class="pre">nshots</span></code> is very small, we can
observe unphysical results where the outcome is higher (lower) than the
maximum (minimum) possible energy. This is because we are using a
Gaussian approximation of the real sampling noise, which should only be
valid when the number of shots is sufficiently large. In the right
panel, we see that for a much larger value of <code class="docutils literal notranslate"><span class="pre">nshots</span></code>, the unphysical
results are suppressed.</p>
</div>
<div class="section" id="getting-the-measurement-variance">
<h2>Getting the measurement variance<a class="headerlink" href="#getting-the-measurement-variance" title="Permalink to this headline">¶</a></h2>
<p>According to the central limit theorem, when <code class="docutils literal notranslate"><span class="pre">nshots</span></code> =
<span class="math notranslate nohighlight">\(\infty\)</span>, the sample mean converges to the true mean (i.e. the
mean obtained directly from the wavefunction), while the standard
deviation of the sample mean tends to zero. For a finite value of
<code class="docutils literal notranslate"><span class="pre">nshots</span></code>, the sample mean itself has a non-zero standard deviation. We
can access this standard deviation by setting the flag
<code class="docutils literal notranslate"><span class="pre">scalar_cost_function=False</span></code> in the constructor of the cost functions.
The cost function then returns both the sample mean and its standard
deviation.</p>
<p>As an implementation note, if we specify a sample size of <code class="docutils literal notranslate"><span class="pre">nshots=0</span></code>,
no noise is added to the mean, and thus the standard deviation is also
set to zero. This case is therefore equivalent to setting <code class="docutils literal notranslate"><span class="pre">nshots</span></code> =
<span class="math notranslate nohighlight">\(\infty\)</span>.</p>
<p>Here is the above code again, with the flag
<code class="docutils literal notranslate"><span class="pre">scalar_cost_function=False</span></code>:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create the cost_function with our ansatz and hamiltonian:</span>
<span class="n">cost_fun</span> <span class="o">=</span> <span class="n">PrepareAndMeasureOnWFSim</span><span class="p">(</span><span class="n">prepare_ansatz</span><span class="o">=</span><span class="n">prepare_ansatz</span><span class="p">,</span>
                                    <span class="n">make_memory_map</span><span class="o">=</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">p</span><span class="p">},</span>
                                    <span class="n">hamiltonian</span><span class="o">=</span><span class="n">hamiltonian</span><span class="p">,</span>
                                    <span class="n">nshots</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
                                    <span class="n">scalar_cost_function</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># get the means and standard deviations</span>
<span class="n">gammas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span>
<span class="n">exp_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">gammas</span><span class="p">)</span>
<span class="n">std_devs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">gammas</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gammas</span><span class="p">):</span>
    <span class="n">exp_vals</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">std_devs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">cost_fun</span><span class="p">([</span><span class="n">v</span><span class="p">])</span>

<span class="c1"># and plot both</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gammas</span><span class="p">,</span> <span class="n">exp_vals</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;cost function&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">gammas</span><span class="p">,</span> <span class="n">exp_vals</span> <span class="o">-</span> <span class="n">std_devs</span><span class="p">,</span> <span class="n">exp_vals</span> <span class="o">+</span> <span class="n">std_devs</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$1\sigma$ interval&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\gamma$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
<img alt="../_images/4_CostFunctionsAndVQE_25_0.png" src="../_images/4_CostFunctionsAndVQE_25_0.png" />
</div>
<div class="section" id="logging-of-the-optimisation-process">
<h2>Logging of the optimisation process<a class="headerlink" href="#logging-of-the-optimisation-process" title="Permalink to this headline">¶</a></h2>
<p>In the previous sections, we focused on single-shot measurements of the
cost function. We now turn our attention to features that facilitate
understanding of the process of cost function optimisation. For
debugging and benchmarking purposes, it is often interesting to
visualise how the optimisation progresses, and at which parameter values
the cost function is called. We therefore provide the option to create a
log of the cost function calls, <code class="docutils literal notranslate"><span class="pre">cost_function.log</span></code>.</p>
<p>Since most typical optimisers (e.g. those contained in
<code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimze</span></code>) expect the objective function to return only
a scalar value (the function value), and not a tuple (i.e. the value and
standard deviation), we cannot use the same methods above to return the
standard deviation; we must set <code class="docutils literal notranslate"><span class="pre">scalar_cost_function</span> <span class="pre">=</span> <span class="pre">True</span></code> (since
this is the default value, we need not actually specify it). Instead, we
will be able to access the standard deviation, as well as other
information, through the optimiser log.</p>
<p>To create the optimisation log, we set <code class="docutils literal notranslate"><span class="pre">enable_logging=True</span></code>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create the cost_function with our ansatz and hamiltonian:</span>
<span class="n">cost_fun</span> <span class="o">=</span> <span class="n">PrepareAndMeasureOnWFSim</span><span class="p">(</span><span class="n">prepare_ansatz</span><span class="o">=</span><span class="n">prepare_ansatz</span><span class="p">,</span>
                                    <span class="n">make_memory_map</span><span class="o">=</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">p</span><span class="p">},</span>
                                    <span class="n">hamiltonian</span><span class="o">=</span><span class="n">hamiltonian</span><span class="p">,</span>
                                    <span class="n">nshots</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                    <span class="n">enable_logging</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># and find the optimal value</span>
<span class="n">gamma0</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># and minimization</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">cost_fun</span><span class="p">,</span> <span class="n">gamma0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;Cobyla&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="n">fun</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.995006044657827</span>
  <span class="n">maxcv</span><span class="p">:</span> <span class="mf">0.0</span>
<span class="n">message</span><span class="p">:</span> <span class="s1">&#39;Optimization terminated successfully.&#39;</span>
   <span class="n">nfev</span><span class="p">:</span> <span class="mi">22</span>
 <span class="n">status</span><span class="p">:</span> <span class="mi">1</span>
<span class="n">success</span><span class="p">:</span> <span class="kc">True</span>
      <span class="n">x</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.59395</span><span class="p">])</span>
</pre></div>
</div>
<p>We can examine the log as follows:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># extract gamma and function value for each of the function calls in the log</span>
<span class="n">gamma_log</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">step</span><span class="o">.</span><span class="n">x</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">cost_fun</span><span class="o">.</span><span class="n">log</span><span class="p">])</span>
<span class="n">fun_log</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">step</span><span class="o">.</span><span class="n">fun</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">cost_fun</span><span class="o">.</span><span class="n">log</span><span class="p">])</span>

<span class="n">fun_log</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span> <span class="mf">2.28877527e-03</span><span class="p">,</span>  <span class="mf">1.00000000e-01</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">7.76303060e-01</span><span class="p">,</span>  <span class="mf">5.40302306e-02</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">8.38799676e-01</span><span class="p">,</span>  <span class="mf">5.40302306e-02</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">8.43648406e-01</span><span class="p">,</span>  <span class="mf">4.16146837e-02</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">7.33479054e-01</span><span class="p">,</span>  <span class="mf">8.01143616e-02</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">9.82648503e-01</span><span class="p">,</span>  <span class="mf">1.78246056e-02</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">9.90595774e-01</span><span class="p">,</span>  <span class="mf">7.07372017e-03</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">9.52429999e-01</span><span class="p">,</span>  <span class="mf">1.94547708e-02</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">1.00017983e+00</span><span class="p">,</span>  <span class="mf">8.29623162e-04</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">9.93486155e-01</span><span class="p">,</span>  <span class="mf">5.41771350e-03</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">1.00214305e+00</span><span class="p">,</span>  <span class="mf">2.29516577e-03</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">1.00105751e+00</span><span class="p">,</span>  <span class="mf">5.41771350e-03</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">9.99635602e-01</span><span class="p">,</span>  <span class="mf">3.85691044e-03</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">9.99537995e-01</span><span class="p">,</span>  <span class="mf">1.51405947e-03</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">1.00011529e+00</span><span class="p">,</span>  <span class="mf">2.68566936e-03</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">1.00042481e+00</span><span class="p">,</span>  <span class="mf">2.09990046e-03</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">9.95741235e-01</span><span class="p">,</span>  <span class="mf">2.39279518e-03</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">1.00024168e+00</span><span class="p">,</span>  <span class="mf">2.24635023e-03</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">9.97431599e-01</span><span class="p">,</span>  <span class="mf">2.31957333e-03</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">1.00111499e+00</span><span class="p">,</span>  <span class="mf">2.28516839e-03</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">1.00284175e+00</span><span class="p">,</span>  <span class="mf">2.30516312e-03</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">9.95006045e-01</span><span class="p">,</span>  <span class="mf">2.31516045e-03</span><span class="p">]])</span>
</pre></div>
</div>
<p>Here, in each of the 22 function evaluations, we log the function value
and its standard deviation. We can visualise this information, along
with the parameter values at each function call:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create an array for the x-axis:</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="s2">&quot;nfev&quot;</span><span class="p">])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fun_log</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;cost_function&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fun_log</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">fun_log</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">fun_log</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">fun_log</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>
                   <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;standard deviation&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">gamma_log</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$\gamma$&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">);</span>
</pre></div>
</div>
<img alt="../_images/4_CostFunctionsAndVQE_31_0.png" src="../_images/4_CostFunctionsAndVQE_31_0.png" />
</div>
<div class="section" id="running-on-the-qvm-or-qpu">
<h2>Running on the QVM or QPU<a class="headerlink" href="#running-on-the-qvm-or-qpu" title="Permalink to this headline">¶</a></h2>
<p>So far, we have run all our experiments on the Wavefunction Simulator.
Eventually, however, we may also want to run them on the the QVM, or
even the real QPU. Since these don’t return a wavefunction, quantities
of interest such as the energy expectation value and its standard
deviation are determined by taking samples from the device. It is
therefore essential to provide a value for the argument <code class="docutils literal notranslate"><span class="pre">nshots</span></code>, and
we instead use the cost function constructors <code class="docutils literal notranslate"><span class="pre">PrepareAndMeasureOnQVM</span></code>
(for general VQE) and <code class="docutils literal notranslate"><span class="pre">QAOACostFunctionOnQVM</span></code> (for QAOA). These behave
mostly identically to <code class="docutils literal notranslate"><span class="pre">PrepareAndMeasureOnWFSim</span></code> and
<code class="docutils literal notranslate"><span class="pre">QAOACostFunctionOnWFSim</span></code>, with a few differences:</p>
<ul class="simple">
<li><p>We must pass an argument <code class="docutils literal notranslate"><span class="pre">qvm</span></code>, which is either an identification
string for a QVM type such as <code class="docutils literal notranslate"><span class="pre">2q-qvm</span></code>, or a connection to a QVM or
QPU (see <a class="reference external" href="http://docs.rigetti.com/en/latest/apidocs/quantum_computer.html">Rigetti’s
docs</a>).</p></li>
<li><p>There is an additional argument <code class="docutils literal notranslate"><span class="pre">base_numshots</span></code>, which acts as a
multiplier of <code class="docutils literal notranslate"><span class="pre">nshots</span></code>. This number is then hard-compiled into the
circuit, whereas <code class="docutils literal notranslate"><span class="pre">nshots</span></code> can be changed dynamically during the
optimisation (however, to do so would require writing a custom
optimiser). This may be of interest for users working with more
sophisticated optimisers. A more detailed explanation can be found in
the FAQs section of the documentation.</p></li>
</ul>
<p>We now walk through the above example again, only this time running on
the QVM. As in <a class="reference external" href="#nshots">Simulating Sampling Noise</a>, we will
calculate the cost function twice - once with 5 samples per point, and
once with 1000 samples per point.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this time we really need a QVM</span>
<span class="n">qvm</span> <span class="o">=</span> <span class="n">get_qc</span><span class="p">(</span><span class="s2">&quot;2q-qvm&quot;</span><span class="p">)</span>

<span class="c1"># sample 5 times</span>
<span class="n">cost_fun</span> <span class="o">=</span> <span class="n">PrepareAndMeasureOnQVM</span><span class="p">(</span><span class="n">prepare_ansatz</span><span class="o">=</span><span class="n">prepare_ansatz</span><span class="p">,</span>
                                  <span class="n">make_memory_map</span><span class="o">=</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">p</span><span class="p">},</span>
                                  <span class="n">hamiltonian</span><span class="o">=</span><span class="n">hamiltonian</span><span class="p">,</span>
                                  <span class="n">qvm</span> <span class="o">=</span> <span class="n">qvm</span><span class="p">,</span>
                                  <span class="n">base_numshots</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                                  <span class="n">nshots</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                                  <span class="n">scalar_cost_function</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">gammas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span>
<span class="n">exp_vals1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">gammas</span><span class="p">)</span>
<span class="n">std_devs1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">gammas</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gammas</span><span class="p">):</span>
    <span class="n">exp_vals1</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">std_devs1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">cost_fun</span><span class="p">([</span><span class="n">v</span><span class="p">])</span>

<span class="c1"># sample 1000 times</span>
<span class="n">cost_fun</span> <span class="o">=</span> <span class="n">PrepareAndMeasureOnQVM</span><span class="p">(</span><span class="n">prepare_ansatz</span><span class="o">=</span><span class="n">prepare_ansatz</span><span class="p">,</span>
                                  <span class="n">make_memory_map</span><span class="o">=</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">p</span><span class="p">},</span>
                                  <span class="n">hamiltonian</span><span class="o">=</span><span class="n">hamiltonian</span><span class="p">,</span>
                                  <span class="n">qvm</span> <span class="o">=</span> <span class="n">qvm</span><span class="p">,</span>
                                  <span class="n">base_numshots</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
                                  <span class="n">nshots</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                                  <span class="n">scalar_cost_function</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">exp_vals2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">gammas</span><span class="p">)</span>
<span class="n">std_devs2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">gammas</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gammas</span><span class="p">):</span>
    <span class="n">exp_vals2</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">std_devs2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">cost_fun</span><span class="p">([</span><span class="n">v</span><span class="p">])</span>
</pre></div>
</div>
<p>Observe how these computations take appreciably longer than in the
section <a class="reference external" href="#nshots">Simulating Sampling Noise</a> above, where we instead
took account of the sampling noise using a Gaussian approximation. In
the present case, we must actually take 1000 samples per point, which
represents a significant computational overhead.</p>
<p>Let us plot the results:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gammas</span><span class="p">,</span> <span class="n">exp_vals1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;cost function&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">gammas</span><span class="p">,</span> <span class="n">exp_vals1</span> <span class="o">-</span> <span class="n">std_devs1</span><span class="p">,</span> <span class="n">exp_vals1</span> <span class="o">+</span> <span class="n">std_devs1</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$1\sigma$ interval&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\gamma$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;nshots=5&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gammas</span><span class="p">,</span> <span class="n">exp_vals2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;cost function&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">gammas</span><span class="p">,</span> <span class="n">exp_vals2</span> <span class="o">-</span> <span class="n">std_devs2</span><span class="p">,</span> <span class="n">exp_vals2</span> <span class="o">+</span> <span class="n">std_devs2</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$1\sigma$ interval&quot;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;nshots=1000&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\gamma$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/4_CostFunctionsAndVQE_35_0.png" src="../_images/4_CostFunctionsAndVQE_35_0.png" />
<p>Evidently, this time there are no values outside of the range [-1,1], as
would also be the case on a real QPU. Furthermore, the plot in the right
panel for <code class="docutils literal notranslate"><span class="pre">nshots=5</span></code> looks considerably different from the one earlier
with simulated sampling noise. The left plot for <code class="docutils literal notranslate"><span class="pre">nshots=1000</span></code>, on the
other hand, looks very similar to the <code class="docutils literal notranslate"><span class="pre">nshots=1000</span></code> plot with the
simulated sampling noise. This shows again that our simulated sampling
noise works well for larger sample numbers.</p>
</div>
<div class="section" id="using-other-optimisers">
<h2>Using other optimisers<a class="headerlink" href="#using-other-optimisers" title="Permalink to this headline">¶</a></h2>
<p>In the above examples, we have used <code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimize</span></code> as our
optimiser, with COYBLA as the specific method. Even within this Scipy
package there are several different methods we could choose - for the
full list, see
<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html">here</a>.
Alternatively, we could use a completely different optimisation package.</p>
<p>Let’s redo the above example using some different methods, comparing the
performance and time taken of each. Here we’ll use the explicit
calculation of the expected energy value.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># create the cost_function with our ansatz and hamiltonian:</span>
<span class="n">cost_fun</span> <span class="o">=</span> <span class="n">PrepareAndMeasureOnWFSim</span><span class="p">(</span><span class="n">prepare_ansatz</span><span class="o">=</span><span class="n">prepare_ansatz</span><span class="p">,</span>
                                    <span class="n">make_memory_map</span><span class="o">=</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">p</span><span class="p">},</span>
                                    <span class="n">hamiltonian</span><span class="o">=</span><span class="n">hamiltonian</span><span class="p">,</span>
                                    <span class="n">nshots</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># exact calculution of energy</span>
                                    <span class="n">scalar_cost_function</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
                                    <span class="n">enable_logging</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="c1"># the initial value</span>
<span class="n">gamma0</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Nelder-Mead&#39;</span><span class="p">,</span> <span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="s1">&#39;Cobyla&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
    <span class="n">initial_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="c1"># minimization</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">cost_fun</span><span class="p">,</span> <span class="n">gamma0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">)</span>

    <span class="n">final_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">total_time</span> <span class="o">=</span> <span class="n">final_time</span> <span class="o">-</span> <span class="n">initial_time</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Method: &#39;</span><span class="p">,</span> <span class="n">method</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Time taken: &#39;</span><span class="p">,</span> <span class="n">total_time</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Result:&#39;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Method</span><span class="p">:</span>  <span class="n">Nelder</span><span class="o">-</span><span class="n">Mead</span>
<span class="n">Time</span> <span class="n">taken</span><span class="p">:</span>  <span class="mf">0.16504526138305664</span>
<span class="n">Result</span><span class="p">:</span>
 <span class="n">final_simplex</span><span class="p">:</span> <span class="p">(</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.5708125</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">1.57075</span>  <span class="p">]]),</span> <span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]))</span>
           <span class="n">fun</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.9999999998692137</span>
       <span class="n">message</span><span class="p">:</span> <span class="s1">&#39;Optimization terminated successfully.&#39;</span>
          <span class="n">nfev</span><span class="p">:</span> <span class="mi">52</span>
           <span class="n">nit</span><span class="p">:</span> <span class="mi">26</span>
        <span class="n">status</span><span class="p">:</span> <span class="mi">0</span>
       <span class="n">success</span><span class="p">:</span> <span class="kc">True</span>
             <span class="n">x</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.5708125</span><span class="p">])</span>


<span class="n">Method</span><span class="p">:</span>  <span class="n">SLSQP</span>
<span class="n">Time</span> <span class="n">taken</span><span class="p">:</span>  <span class="mf">0.029027700424194336</span>
<span class="n">Result</span><span class="p">:</span>
     <span class="n">fun</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.9999999984694352</span>
     <span class="n">jac</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">5.53205609e-05</span><span class="p">])</span>
 <span class="n">message</span><span class="p">:</span> <span class="s1">&#39;Optimization terminated successfully.&#39;</span>
    <span class="n">nfev</span><span class="p">:</span> <span class="mi">10</span>
     <span class="n">nit</span><span class="p">:</span> <span class="mi">3</span>
    <span class="n">njev</span><span class="p">:</span> <span class="mi">3</span>
  <span class="n">status</span><span class="p">:</span> <span class="mi">0</span>
 <span class="n">success</span><span class="p">:</span> <span class="kc">True</span>
       <span class="n">x</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.57085165</span><span class="p">])</span>


<span class="n">Method</span><span class="p">:</span>  <span class="n">Cobyla</span>
<span class="n">Time</span> <span class="n">taken</span><span class="p">:</span>  <span class="mf">0.06922435760498047</span>
<span class="n">Result</span><span class="p">:</span>
     <span class="n">fun</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.9999999954355244</span>
   <span class="n">maxcv</span><span class="p">:</span> <span class="mf">0.0</span>
 <span class="n">message</span><span class="p">:</span> <span class="s1">&#39;Optimization terminated successfully.&#39;</span>
    <span class="n">nfev</span><span class="p">:</span> <span class="mi">24</span>
  <span class="n">status</span><span class="p">:</span> <span class="mi">1</span>
 <span class="n">success</span><span class="p">:</span> <span class="kc">True</span>
       <span class="n">x</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.57070078</span><span class="p">])</span>
</pre></div>
</div>
<p>Clearly, all three tested optimisers found the same minimum. However, it
took Nelder-Mead 52 function evaluations for convergence, while COBYLA
and SLSQP needed only 10 and 24 function evaluations, respectively. The
latter two therefore seem to be superior.</p>
<p>However, it is important to note that we set <code class="docutils literal notranslate"><span class="pre">nshots=0</span></code>, meaning that
the exact expectation value is returned by the cost function. If we had
set <code class="docutils literal notranslate"><span class="pre">nshots</span></code> to some finite value, SLSQP would have had a much harder
time, because it is a gradient-based algorithm: it decides where to move
in the next step by computing the gradient using finite differences. To
work effectively, this requires exact values of the cost function, which
is not possible when taking samples (unless, of course, an infinite
number of samples is taken).</p>
<p>We can also use a different optimisation library altogether. Here we
demonstrate a Bayesian optimisation function from <code class="docutils literal notranslate"><span class="pre">scikit-optimize</span></code>
(docs <a class="reference external" href="https://scikit-optimize.github.io/#skopt.gp_minimize">here</a>).</p>
<p><strong>Note that to run the cell below you will need to install
scikit-optimize.</strong></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">skopt</span> <span class="kn">import</span> <span class="n">gp_minimize</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="n">initial_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">out</span> <span class="o">=</span> <span class="n">gp_minimize</span><span class="p">(</span><span class="n">cost_fun</span><span class="p">,</span>
                  <span class="n">n_calls</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                  <span class="n">dimensions</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">)],</span>
                  <span class="n">x0</span><span class="o">=</span><span class="n">gamma0</span><span class="p">)</span>

<span class="n">final_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">total_time</span> <span class="o">=</span> <span class="n">final_time</span> <span class="o">-</span> <span class="n">initial_time</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Method: &#39;</span><span class="p">,</span> <span class="s1">&#39;Bayesian Optimisation&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Time taken: &#39;</span><span class="p">,</span> <span class="n">total_time</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Result:&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Method</span><span class="p">:</span>  <span class="n">Bayesian</span> <span class="n">Optimisation</span>
<span class="n">Time</span> <span class="n">taken</span><span class="p">:</span>  <span class="mf">0.9499242305755615</span>
<span class="n">Result</span><span class="p">:</span>
          <span class="n">fun</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.9999951032029182</span>
    <span class="n">func_vals</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="o">-</span><span class="mf">0.10881609</span><span class="p">,</span>  <span class="mf">0.95360189</span><span class="p">,</span>  <span class="mf">0.41721697</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.98896448</span><span class="p">,</span>
       <span class="o">-</span><span class="mf">0.99803173</span><span class="p">,</span>  <span class="mf">0.93563543</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.97851649</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00964807</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.41018182</span><span class="p">,</span>
       <span class="o">-</span><span class="mf">0.72190887</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9999951</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.99999503</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.99998915</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.99999488</span><span class="p">])</span>
       <span class="n">models</span><span class="p">:</span> <span class="p">[</span><span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">copy_X_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">kernel</span><span class="o">=</span><span class="mi">1</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span> <span class="o">+</span> <span class="n">WhiteKernel</span><span class="p">(</span><span class="n">noise_level</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                         <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span>
                         <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;fmin_l_bfgs_b&#39;</span><span class="p">,</span>
                         <span class="n">random_state</span><span class="o">=</span><span class="mi">612601979</span><span class="p">),</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">copy_X_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">kernel</span><span class="o">=</span><span class="mi">1</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span> <span class="o">+</span> <span class="n">WhiteKernel</span><span class="p">(</span><span class="n">noise_level</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                         <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span>
                         <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;fmin_l_bfgs_b&#39;</span><span class="p">,</span>
                         <span class="n">random_state</span><span class="o">=</span><span class="mi">612601979</span><span class="p">),</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">copy_X_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">kernel</span><span class="o">=</span><span class="mi">1</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span> <span class="o">+</span> <span class="n">WhiteKernel</span><span class="p">(</span><span class="n">noise_level</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                         <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span>
                         <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;fmin_l_bfgs_b&#39;</span><span class="p">,</span>
                         <span class="n">random_state</span><span class="o">=</span><span class="mi">612601979</span><span class="p">),</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">copy_X_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">kernel</span><span class="o">=</span><span class="mi">1</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span> <span class="o">+</span> <span class="n">WhiteKernel</span><span class="p">(</span><span class="n">noise_level</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                         <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span>
                         <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;fmin_l_bfgs_b&#39;</span><span class="p">,</span>
                         <span class="n">random_state</span><span class="o">=</span><span class="mi">612601979</span><span class="p">),</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">copy_X_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">kernel</span><span class="o">=</span><span class="mi">1</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span> <span class="o">+</span> <span class="n">WhiteKernel</span><span class="p">(</span><span class="n">noise_level</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                         <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span>
                         <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;fmin_l_bfgs_b&#39;</span><span class="p">,</span>
                         <span class="n">random_state</span><span class="o">=</span><span class="mi">612601979</span><span class="p">)]</span>
 <span class="n">random_state</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">mtrand</span><span class="o">.</span><span class="n">RandomState</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7f95b91531f8</span><span class="o">&gt;</span>
        <span class="n">space</span><span class="p">:</span> <span class="n">Space</span><span class="p">([</span><span class="n">Real</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">6.283185307179586</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="s1">&#39;normalize&#39;</span><span class="p">)])</span>
        <span class="n">specs</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;args&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;func&#39;</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">entropica_qaoa</span><span class="o">.</span><span class="n">vqe</span><span class="o">.</span><span class="n">cost_function</span><span class="o">.</span><span class="n">PrepareAndMeasureOnWFSim</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7f959d70acc0</span><span class="o">&gt;</span><span class="p">,</span> <span class="s1">&#39;dimensions&#39;</span><span class="p">:</span> <span class="n">Space</span><span class="p">([</span><span class="n">Real</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">6.283185307179586</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="s1">&#39;normalize&#39;</span><span class="p">)]),</span> <span class="s1">&#39;base_estimator&#39;</span><span class="p">:</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">copy_X_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">kernel</span><span class="o">=</span><span class="mi">1</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">),</span>
                         <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span>
                         <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;fmin_l_bfgs_b&#39;</span><span class="p">,</span>
                         <span class="n">random_state</span><span class="o">=</span><span class="mi">612601979</span><span class="p">),</span> <span class="s1">&#39;n_calls&#39;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span> <span class="s1">&#39;n_random_starts&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;acq_func&#39;</span><span class="p">:</span> <span class="s1">&#39;gp_hedge&#39;</span><span class="p">,</span> <span class="s1">&#39;acq_optimizer&#39;</span><span class="p">:</span> <span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;x0&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;y0&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;random_state&#39;</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">mtrand</span><span class="o">.</span><span class="n">RandomState</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7f95b91531f8</span><span class="o">&gt;</span><span class="p">,</span> <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;callback&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;n_points&#39;</span><span class="p">:</span> <span class="mi">10000</span><span class="p">,</span> <span class="s1">&#39;n_restarts_optimizer&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;xi&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span> <span class="s1">&#39;kappa&#39;</span><span class="p">:</span> <span class="mf">1.96</span><span class="p">,</span> <span class="s1">&#39;n_jobs&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span> <span class="s1">&#39;function&#39;</span><span class="p">:</span> <span class="s1">&#39;base_minimize&#39;</span><span class="p">}</span>
            <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="mf">4.709259507241108</span><span class="p">]</span>
      <span class="n">x_iters</span><span class="p">:</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.174153314509717</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.2649813051127539</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.7112117865462193</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.563688783161364</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.775141057759561</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.210055025140235</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.920046772171743</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.273537089495047</span><span class="p">],</span> <span class="p">[</span><span class="mf">5.860531890630306</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.9481495422966617</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.709259507241108</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.709236727625187</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.707730206022452</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.7091883971865585</span><span class="p">]]</span>
</pre></div>
</div>
<p>The usage of Bayesian optimisation to solve this very simple problem is
slightly overkill. However, for VQE or QAOA problems where the cost
function evaluations themselves are expensive, and the parameter space
itself is not too large, Bayesian optimisation may be worth
investigating. A good primer can be found
<a class="reference external" href="https://arxiv.org/pdf/1807.02811.pdf">here</a>.</p>
</div>
<div class="section" id="towards-qaoa">
<h2>Towards QAOA<a class="headerlink" href="#towards-qaoa" title="Permalink to this headline">¶</a></h2>
<p>A more detailled explanation of our QAOA library can be found in the
Notebooks <a class="reference internal" href="1_AnExampleWorkflow.html#anexampleworkflow"><span class="std std-ref">First steps: An example workflow</span></a>, <a class="reference internal" href="2_ParameterClasses.html#parameterclasses"><span class="std std-ref">Working with the Parameter classes</span></a>,
and <a class="reference internal" href="3_AdvancedParameterClasses.html#advancedparameterclasses"><span class="std std-ref">Advanced QAOA parameter classes</span></a>. Here we simply explain how it
can be regarded as a special case of VQE.</p>
<p>For QAOA - which was originally designed for solving classical
optimization problems - the Hamiltonian is diagonal in the computational
basis, and typically contains at most 2-qubit terms (there is nothing to
prevent one from considering k-qubit terms, however the limitations of
near-term hardware make the k = 2 case the most practically feasible).</p>
<p>Let’s set up a simple Hamiltonian.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hamiltonian</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">hamiltonian</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PauliTerm</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">PauliTerm</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">hamiltonian</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PauliTerm</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">))</span>
<span class="n">hamiltonian</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PauliTerm</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">hamiltonian</span> <span class="o">=</span> <span class="n">PauliSum</span><span class="p">(</span><span class="n">hamiltonian</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">hamiltonian</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">+</span><span class="mi">0</span><span class="n">j</span><span class="p">)</span><span class="o">*</span><span class="n">Z0</span><span class="o">*</span><span class="n">Z1</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.8</span><span class="o">+</span><span class="mi">0</span><span class="n">j</span><span class="p">)</span><span class="o">*</span><span class="n">Z0</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">+</span><span class="mi">0</span><span class="n">j</span><span class="p">)</span><span class="o">*</span><span class="n">Z1</span>
</pre></div>
</div>
<p>Since the parameters for a QAOA circuit have more structure than just a
flat array, and there exist multiple possible parametrisations, we
provide special classes to hold the parameters for a QAOA circuit. We
will use the <code class="docutils literal notranslate"><span class="pre">FourierParams</span></code> class here. We can create these initial
parameters as follows:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="n">FourierParams</span><span class="o">.</span><span class="n">linear_ramp_from_hamiltonian</span><span class="p">(</span><span class="n">hamiltonian</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p>The QAOA cost function has a fixed structure, with a corresponding fixed
state preparation program. We therefore provide special cost functions
for QAOA, which inherit most of the behaviour from
<code class="docutils literal notranslate"><span class="pre">vqe.cost_functions.PrepareAndMeasure...</span></code>. They are created via</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qaoa_cost_fun</span> <span class="o">=</span> <span class="n">QAOACostFunctionOnWFSim</span><span class="p">(</span><span class="n">hamiltonian</span><span class="p">,</span>
                                        <span class="n">params</span><span class="p">,</span>
                                        <span class="n">nshots</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                                        <span class="n">enable_logging</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Unlike for <code class="docutils literal notranslate"><span class="pre">PrepareAndMeasureOnWFSim</span></code>, we didn’t have to pass a state
preparation circuit <code class="docutils literal notranslate"><span class="pre">prepare_ansatz</span></code> or function to generate memory
maps <code class="docutils literal notranslate"><span class="pre">make_memory_map</span></code> to <code class="docutils literal notranslate"><span class="pre">QAOACostFunctionOnWFSim</span></code>. These are
already fixed by the fact that we want to run QAOA with a given cost
Hamiltonian. Instead, we have to pass the QAOA parameters <code class="docutils literal notranslate"><span class="pre">params</span></code> to
the cost function.</p>
<p>If we want to find the optimal parameters, we have to provide our
optimiser with some initial parameter set. The object <code class="docutils literal notranslate"><span class="pre">params</span></code>
contains information on both the problem hyperparameters, as well as the
variable parameters to be optimised - see <a class="reference internal" href="2_ParameterClasses.html#parameterclasses"><span class="std std-ref">Working with the Parameter classes</span></a>
for further information.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Hyperparameters</span><span class="p">:</span>
    <span class="n">register</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">qubits_singles</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">qubits_pairs</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">Parameters</span><span class="p">:</span>
    <span class="n">v</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.35</span> <span class="mf">0.</span>   <span class="mf">0.</span>  <span class="p">]</span>
    <span class="n">u</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.35</span> <span class="mf">0.</span>   <span class="mf">0.</span>  <span class="p">]</span>
</pre></div>
</div>
<p>We can obtain a 1D array with all of our variable parameters - here
denoted <code class="docutils literal notranslate"><span class="pre">u</span></code> and <code class="docutils literal notranslate"><span class="pre">v</span></code> - using the <code class="docutils literal notranslate"><span class="pre">params.raw()</span></code> method: we can
subsequently pass these to an optimiser, such as a method from
<code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimize</span></code>:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p0</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">raw</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">qaoa_cost_fun</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;Cobyla&quot;</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;maxiter&quot;</span><span class="p">:</span> <span class="mi">500</span><span class="p">})</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The output of scipy.optimize.minimize:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">out</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> And hamiltonian as a matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">lifted_pauli</span><span class="p">(</span><span class="n">hamiltonian</span><span class="p">,</span> <span class="n">hamiltonian</span><span class="o">.</span><span class="n">get_qubits</span><span class="p">()))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">output</span> <span class="n">of</span> <span class="n">scipy</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">:</span>
      <span class="n">fun</span><span class="p">:</span> <span class="o">-</span><span class="mf">1.0980860380605737</span>
   <span class="n">maxcv</span><span class="p">:</span> <span class="mf">0.0</span>
 <span class="n">message</span><span class="p">:</span> <span class="s1">&#39;Optimization terminated successfully.&#39;</span>
    <span class="n">nfev</span><span class="p">:</span> <span class="mi">53</span>
  <span class="n">status</span><span class="p">:</span> <span class="mi">1</span>
 <span class="n">success</span><span class="p">:</span> <span class="kc">True</span>
       <span class="n">x</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.33338502</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0362319</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.00113797</span><span class="p">,</span>  <span class="mf">0.44507301</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.11073208</span><span class="p">,</span>
       <span class="o">-</span><span class="mf">0.02014963</span><span class="p">])</span>

 <span class="n">And</span> <span class="n">hamiltonian</span> <span class="k">as</span> <span class="n">a</span> <span class="n">matrix</span><span class="p">:</span>
 <span class="p">[[</span><span class="o">-</span><span class="mf">0.7</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span>  <span class="mf">0.</span> <span class="o">+</span><span class="mf">0.</span><span class="n">j</span>  <span class="mf">0.</span> <span class="o">+</span><span class="mf">0.</span><span class="n">j</span>  <span class="mf">0.</span> <span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">0.</span> <span class="o">+</span><span class="mf">0.</span><span class="n">j</span> <span class="o">-</span><span class="mf">0.3</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span>  <span class="mf">0.</span> <span class="o">+</span><span class="mf">0.</span><span class="n">j</span>  <span class="mf">0.</span> <span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">0.</span> <span class="o">+</span><span class="mf">0.</span><span class="n">j</span>  <span class="mf">0.</span> <span class="o">+</span><span class="mf">0.</span><span class="n">j</span>  <span class="mf">2.3</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span>  <span class="mf">0.</span> <span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">0.</span> <span class="o">+</span><span class="mf">0.</span><span class="n">j</span>  <span class="mf">0.</span> <span class="o">+</span><span class="mf">0.</span><span class="n">j</span>  <span class="mf">0.</span> <span class="o">+</span><span class="mf">0.</span><span class="n">j</span> <span class="o">-</span><span class="mf">1.3</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">]]</span>
</pre></div>
</div>
<p>Examining the logs this time involves a little extra work. The logging
functionality simply appends the array of current parameters (i.e. at
any step in the optimisation) to the log. For instance, the 10th log
entry reads:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qaoa_cost_fun</span><span class="o">.</span><span class="n">log</span><span class="p">[</span><span class="mi">9</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">LogEntry</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">array</span><span class="p">([</span> <span class="mf">0.57769948</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.06151086</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05447635</span><span class="p">,</span>  <span class="mf">0.29858683</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0309951</span> <span class="p">,</span>
       <span class="o">-</span><span class="mf">0.01725329</span><span class="p">]),</span> <span class="n">fun</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.6538453689892179</span><span class="p">,</span> <span class="mf">0.027969997721439686</span><span class="p">))</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">LogEntry</span></code> array contains the <code class="docutils literal notranslate"><span class="pre">u</span></code> and <code class="docutils literal notranslate"><span class="pre">v</span></code> parameters for all
three values of the Fourier parameter <code class="docutils literal notranslate"><span class="pre">q</span></code>. Meanwhile, the <code class="docutils literal notranslate"><span class="pre">fun</span></code>
entry is of the form (function value, standard deviation).</p>
<p>To disentangle the <code class="docutils literal notranslate"><span class="pre">u</span></code> and <code class="docutils literal notranslate"><span class="pre">v</span></code> parameters, we can pipe them through
the <code class="docutils literal notranslate"><span class="pre">params</span></code> instance again, using the method <code class="docutils literal notranslate"><span class="pre">.update_from_raw()</span></code>:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># logs of the parameter values</span>
<span class="n">u_log</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">v_log</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">qaoa_cost_fun</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
    <span class="n">params</span><span class="o">.</span><span class="n">update_from_raw</span><span class="p">(</span><span class="n">step</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
    <span class="n">u_log</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">u</span><span class="p">)</span>
    <span class="n">v_log</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>

<span class="c1"># create arrays from the lists</span>
<span class="n">u_log</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">u_log</span><span class="p">)</span>
<span class="n">v_log</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">v_log</span><span class="p">)</span>

<span class="c1"># log of the function values</span>
<span class="n">fun_log</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">step</span><span class="o">.</span><span class="n">fun</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">qaoa_cost_fun</span><span class="o">.</span><span class="n">log</span><span class="p">])</span>

<span class="c1"># create an array for the x-axis:</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="s2">&quot;nfev&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>Now we can plot the information in the log:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fun_log</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;cost_function(p)&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fun_log</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">fun_log</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">fun_log</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">fun_log</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">v_log</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">f</span><span class="s2">&quot;v[{i}]&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">u_log</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">f</span><span class="s2">&quot;u[{i}]&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">);</span>
</pre></div>
</div>
<img alt="../_images/4_CostFunctionsAndVQE_58_0.png" src="../_images/4_CostFunctionsAndVQE_58_0.png" />
<p>We can also plot the final, optimal parameters alone, with the built-in
<code class="docutils literal notranslate"><span class="pre">.params.plot()</span></code> function.</p>
<p>Note: In this case we are working with <code class="docutils literal notranslate"><span class="pre">Fourier</span></code> parameters <code class="docutils literal notranslate"><span class="pre">u</span></code> and
<code class="docutils literal notranslate"><span class="pre">v</span></code>, but the actual circuit parameters <code class="docutils literal notranslate"><span class="pre">betas</span></code> and <code class="docutils literal notranslate"><span class="pre">gammas</span></code> are
generally those of interest. When we call the <code class="docutils literal notranslate"><span class="pre">.plot()</span></code> function on a
set of <code class="docutils literal notranslate"><span class="pre">Fourier</span></code> params, they are automatically converted back to the
<code class="docutils literal notranslate"><span class="pre">betas</span></code> and <code class="docutils literal notranslate"><span class="pre">gammas</span></code>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="o">.</span><span class="n">update_from_raw</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">])</span>
<span class="n">params</span><span class="o">.</span><span class="n">plot</span><span class="p">();</span>
</pre></div>
</div>
<img alt="../_images/4_CostFunctionsAndVQE_60_0.png" src="../_images/4_CostFunctionsAndVQE_60_0.png" />
</div>
<div class="section" id="appendix-simulated-measurement-noise-statistics-implementation-details">
<h2>Appendix: Simulated measurement noise - statistics implementation details<a class="headerlink" href="#appendix-simulated-measurement-noise-statistics-implementation-details" title="Permalink to this headline">¶</a></h2>
<p>The attentive observer will have noticed that when we add simulated
measurement noise via the <code class="docutils literal notranslate"><span class="pre">nshots</span></code> option on the Wavefunction
Simulator, we sometimes find function values below (above) the minimum
(maximum) eigenvalue of the Hamiltonian. As explained above, this is
because we “fake” the sampling noise when using the wavefunction-based
cost functions <code class="docutils literal notranslate"><span class="pre">PrepareAndMeasureOnWFSim</span></code> and
<code class="docutils literal notranslate"><span class="pre">QAOACostFunctionOnWFSim</span></code>. We first calculate the true energy
expectation value and variance via</p>
<div class="math notranslate nohighlight">
\[E(\vec{\gamma}) = \left&lt;\psi(\vec{\gamma})\left| \hat{H} \right| \psi(\vec{\gamma})\right&gt;
\qquad\mathrm{and}\qquad
\mathrm{var}(E)(\vec{\gamma}) = \left&lt;\psi(\vec{\gamma})\left| \hat{H}^2 \right| \psi(\vec{\gamma})\right&gt; - \left&lt;\psi(\vec{\gamma})\left| \hat{H} \right| \psi(\vec{\gamma})\right&gt;^2\]</div>
<p>and then return, in accordance with the <a class="reference external" href="https://en.wikipedia.org/wiki/Central_limit_theorem">central limit
theorem</a>, this
energy expectation value plus appropriately scaled Gaussian noise, along
with the standard deviation of the mean:</p>
<div class="math notranslate nohighlight">
\[\mathrm{cost\_function} (\vec{\gamma}) =
\left(
    E(\vec{\gamma}) +  \mathcal{N}\left(0, \sqrt{\frac{\mathrm{var}(E)(\vec{\gamma})}{\mathrm{nshots}}}\right),
\sqrt{\frac{\mathrm{var}(E)(\vec{\gamma})}{\mathrm{nshots}}}
\right)\]</div>
<p>Now in some examples above, for the purposes of illustrating the
limitations of this method, we used extremely small numbers of shots
<span class="math notranslate nohighlight">\(\leq 10\)</span>. For such small values of <code class="docutils literal notranslate"><span class="pre">nshots</span></code>, the central limit
theorem does not hold, and we get the afore mentioned unphysical results
on occasion. In practice, in a real VQE or QAOA run, one would in any
case take much larger numbers of shots.</p>
<p>On the other hand, the sampling-based cost functions
<code class="docutils literal notranslate"><span class="pre">PrepareAndMeasureOnQVM</span></code> and <code class="docutils literal notranslate"><span class="pre">QAOACostFunctionOnQVM</span></code> don’t need to
‘fake’ the sampling noise, and we are guaranteed to get physical
results. This comes at the cost of much slower simulations, since many
random numbers have to be generated.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="5_QAOAUtilities.html" class="btn btn-neutral float-right" title="Utility functions for QAOA" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="3_AdvancedParameterClasses.html" class="btn btn-neutral float-left" title="Advanced QAOA parameter classes" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, EntropicaLabs

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>