{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAOA Implementation Demo\n",
    "**Author: Cooper Midroni**\n",
    "<br>\n",
    "cooper@entropicalabs.com\n",
    "\n",
    "In this notebook we demonstrate a start-to-finish project workflow for using Quantum Approximate Optimization Algorithm to cluster a simple dataset. Along the way, we will explain the major concepts of QAOA and build intuition as to how QAOA can be used to solve clustering problems. This notebook will steer away from heavy mathematical explanations in favor of a higher level overview of the algorithm's core components. We recognize that understanding QAOA's mathematics is a valuable lens for using this tool, and have created a second notebook for the courageous few who wish to build this deeper understanding.\n",
    "\n",
    "We recommend to all that they first use this notebook, as the two are made to provide one cohesive narrative and each contain unique information.\n",
    "\n",
    "## Index\n",
    "1. Variational Hybrid Algorithms\n",
    "2. Understanding MAXCUT\n",
    "3. Cost Function\n",
    "4. Adiabatic Computing\n",
    "5. Understanding QAOA Parameter Schemes\n",
    "6. Additional Workflow Tools\n",
    "7. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Variational Hybrid Algorithms\n",
    "\n",
    "We often take for granted the many decades of progress that lead to today's widespread use of classical computers. As memory and compute power become ever cheapened by Moore's Law, the pressure to find optimal resource allocations for algorithms shrinks away. However, with quantum computers in their early stages, they still feel this daunting requirement. In response to this, a family of algorithms known as *variational hybrid quantum-classical algorithms* was created, with the notion that quantum resources can be made more useful when partnered with classical routines. The Quantum Approximate Optimization Algorithm (QAOA), belongs to the family of variatonal hybrid algorithms. \n",
    "\n",
    "We can infer a lot from merely unpacking this name. The presence of '*variational*' tells us these algorithms will follow an iterative approach, while '*hybrid*' tells us they will leverage the use of both quantum and classical computers. In fact, this describes the main flow of the algorithm, with all that needs be answered is *when* does this iteration stop and *what* information is passed between devices.\n",
    "\n",
    "<center><img src=\"imgs/general_variational.png\" style=\"width:600px\";></center>\n",
    "<center><i> A visual representation of a generic variational hybrid quantum-classical algorithm.</i></center>\n",
    "\n",
    "To answer the question of *what*, we note that the main goal of QAOA is optimize a set of **parameters**, which we denote as $\\vec{\\gamma}$ and $\\vec{\\beta}$. You'll notice that these symbols are vectors, as such they are $n-$length. We discuss later what aspects of our problem decide the value of $n$ in the second notebook. \n",
    "\n",
    "$\\vec{\\gamma}$ and $\\vec{\\beta}$ parameterize a **cost function** which is evaluated with our **Quantum Circuit** to produce a cost value. This output value is input to the optimizer, and is used to determine whether the nudging of our parameters is in a direction of lower cost. We will sometimes call the cost value an **expectation value**, represented by $\\langle\\psi|Cost|\\psi\\rangle$, which is the expected value of the function $Cost$ over the **wave function** $\\psi$. If you were caught off guard by the term 'wave function' (a common terminology in physics), then it is equally as effective to think of $\\langle\\psi|Cost|\\psi\\rangle$ as being the notion of cost as in the more traditional machine learning sense. The **Classical Optimizer** will return updated parameters to the quantum circuit for re-evaluation, and the cycle repeats. \n",
    "\n",
    "*When* does this algorithm stop? Well, once a stopping criterion is met of course. This criterion is often a pre-defined maximum number of iterations, or occurs after a repeat number of evaluations land within the same threshold of convergence (a tolerance for the cost value in which we consider numbers within an $\\epsilon-$window the same). Once this criterion is met, the **optimized parameters** are returned and used to define the solution. \n",
    "\n",
    "<br>\n",
    "<center><img src=\"imgs/variational.png\" style=\"width:600px\";></center>\n",
    "<center><i> A visual representation of QAOA in the format of a variational hybrid algorithm.</i></center>\n",
    "<br>\n",
    "\n",
    "The above description should leave you with many questions.\n",
    "- How does the above process solve a clustering problem?\n",
    "- How exactly do $\\vec{\\gamma}$ and $\\vec{\\beta}$ define the solution?\n",
    "- How do we define a meaningful cost function for our problem?\n",
    "- What in the world is a wave function?\n",
    "\n",
    "We hope to answer these and more. For now, if you feel comfortable with the critical vocabulary of QAOA (the bolded words), then you'll be well prepared for the explanations below.\n",
    "***\n",
    "## Data Preparation\n",
    "Now let's get to the fun part! We will import our data and define the problem setting as a highly manicured example for this clustering demo. \n",
    "\n",
    "The dataset we will be using is the **Pokemon dataset**, which can be found on [Github](https://gist.github.com/armgilles/194bcff35001e7eb53a2a8b441e8b2c6). In our journey to Catch 'Em All, we will attempt to cluster Pokemon into Legendary and non-Legendary classes. \n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Charmeleon</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name Type 1  Type 2  Total  HP  Attack  Defense  Sp. Atk  Sp. Def  \\\n",
       "ID                                                                            \n",
       "1    Bulbasaur  Grass  Poison    318  45      49       49       65       65   \n",
       "2      Ivysaur  Grass  Poison    405  60      62       63       80       80   \n",
       "3     Venusaur  Grass  Poison    525  80      82       83      100      100   \n",
       "4   Charmander   Fire     NaN    309  39      52       43       60       50   \n",
       "5   Charmeleon   Fire     NaN    405  58      64       58       80       65   \n",
       "\n",
       "    Speed  Generation  Legendary  \n",
       "ID                                \n",
       "1      45           1      False  \n",
       "2      60           1      False  \n",
       "3      80           1      False  \n",
       "4      65           1      False  \n",
       "5      80           1      False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/pokemon.csv')\n",
    "df = df.set_index('#') #index pokemon by their ID number\n",
    "df = df.rename_axis('ID') #rename axis to 'ID' instead of '#'\n",
    "df = df.loc[~df.index.duplicated(keep='first')] #drop duplicates\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid the many bells and whistles of later iterations of Pokemon games, we'll stick to our roots and only consider Pokemon from the first three generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Weezing</td>\n",
       "      <td>Poison</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490</td>\n",
       "      <td>65</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Hoppip</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Flying</td>\n",
       "      <td>250</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Chinchou</td>\n",
       "      <td>Water</td>\n",
       "      <td>Electric</td>\n",
       "      <td>330</td>\n",
       "      <td>75</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rattata</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>253</td>\n",
       "      <td>30</td>\n",
       "      <td>56</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Baltoy</td>\n",
       "      <td>Ground</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>300</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name  Type 1    Type 2  Total  HP  Attack  Defense  Sp. Atk  Sp. Def  \\\n",
       "ID                                                                              \n",
       "110   Weezing  Poison       NaN    490  65      90      120       85       70   \n",
       "187    Hoppip   Grass    Flying    250  35      35       40       35       55   \n",
       "170  Chinchou   Water  Electric    330  75      38       38       56       56   \n",
       "19    Rattata  Normal       NaN    253  30      56       35       25       35   \n",
       "343    Baltoy  Ground   Psychic    300  40      40       55       40       70   \n",
       "\n",
       "     Speed  Generation  Legendary  \n",
       "ID                                 \n",
       "110     60           1      False  \n",
       "187     50           2      False  \n",
       "170     67           2      False  \n",
       "19      72           1      False  \n",
       "343     55           3      False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[df['Generation']<=3]\n",
    "df.sample(frac=1).head() #sample the whole dataset (frac=1) to shuffle the arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Non-Legendary Pokemon: 0.95\n",
      "Percent of Legendary Pokemon: 0.05\n"
     ]
    }
   ],
   "source": [
    "print('Percent of Non-Legendary Pokemon: %.2f' %((df.Legendary.count()-df.Legendary.sum())/df.Legendary.count()))\n",
    "print('Percent of Legendary Pokemon: %.2f' %((df.Legendary.sum())/df.Legendary.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the classes are quite unevenly distributed. To remedy this, we will randomly select 5 Legendary and 5 Non-Legendary Pokemon to act as our samples to be clustered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "legendary = df.loc[df['Legendary'] == True].sample(5)\n",
    "non_legendary = df.loc[df['Legendary'] == False].sample(5)\n",
    "pokemon = pd.concat([legendary,non_legendary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further simplify the problem, and not worry about the encoding of categorical data, we will only consider numerical values in our clustering of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['Total','HP','Attack','Defense','Sp. Atk','Sp. Def','Speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>670</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>680</td>\n",
       "      <td>105</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>680</td>\n",
       "      <td>106</td>\n",
       "      <td>90</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>154</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>600</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>580</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>85</td>\n",
       "      <td>125</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total   HP  Attack  Defense  Sp. Atk  Sp. Def  Speed\n",
       "ID                                                       \n",
       "382    670  100     100       90      150      140     90\n",
       "384    680  105     150       90      150       90     95\n",
       "249    680  106      90      130       90      154    110\n",
       "386    600   50     150       50      150       50    150\n",
       "145    580   90      90       85      125       90    100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pokemon['Legendary']\n",
    "data = pokemon[numerical_columns].copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataset which is ready to be processed, but we may not be exactly clear on what to do with it. For that we must further understand how the QAOA process detailed above is actually used to solve a clustering problem.\n",
    "***\n",
    "## Understanding Maxcut\n",
    "\n",
    "As laid out by [Rigetti's paper on QAOA](https://arxiv.org/pdf/1712.05771.pdf), there are a number of important steps that we must follow to map the problem of clustering into a format which QAOA can process. Broadly speaking, QAOA solves the **MAXCUT** problem, in which a graph of $n$ vertices is separated into two complementary subsets, $S$ and $S^{c}$, such that the number of edges between $S$ and $S^{c}$ is as large as possible.\n",
    "<br>\n",
    "<br>\n",
    "<center><img src=\"imgs/maxcut.png\"></center>\n",
    "<center><i> A depiction of the maxcut problem, displaying a cut which separates white and black vertices.</i></center>\n",
    "<br>\n",
    "<br>    \n",
    "This problem can be made more sophisticated by adding numerical values as <i>weights</i> to the edges, such that the best solution maximizes the sum of weights which separate $S$ and $S^{c}$. This is precisely the approach we take in using MAXCUT to cluster our data. \n",
    "\n",
    "We allow the weights associated to each edge to be some notion of distance between points. In this way, the sets dictated by our optimal cut, $S$ and $S^{c}$, separate the data into binary clusters which are maximally distant (and hence, maximally dissimilar) from one another.\n",
    "\n",
    "From our current understanding, we can already begin to formulate some first steps in preparing our data to fit this frameowrk.\n",
    "\n",
    "We can use SciPy's built in `distance_matrix` function to easily turn this set of points into the desired matrix of pairwise distances. Recall, that a distance matrix can be interpretted as the adjacency matrix of a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cdist(data.values,data.values,'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID</th>\n",
       "      <th>382</th>\n",
       "      <th>384</th>\n",
       "      <th>249</th>\n",
       "      <th>386</th>\n",
       "      <th>145</th>\n",
       "      <th>330</th>\n",
       "      <th>78</th>\n",
       "      <th>142</th>\n",
       "      <th>101</th>\n",
       "      <th>168</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.763500</td>\n",
       "      <td>77.665951</td>\n",
       "      <td>152.315462</td>\n",
       "      <td>107.470926</td>\n",
       "      <td>177.763888</td>\n",
       "      <td>198.116128</td>\n",
       "      <td>197.484177</td>\n",
       "      <td>227.156334</td>\n",
       "      <td>311.126984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>71.763500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.551299</td>\n",
       "      <td>125.099960</td>\n",
       "      <td>120.415946</td>\n",
       "      <td>183.983695</td>\n",
       "      <td>204.939015</td>\n",
       "      <td>200.124961</td>\n",
       "      <td>243.823707</td>\n",
       "      <td>318.355148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>77.665951</td>\n",
       "      <td>114.551299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>188.552380</td>\n",
       "      <td>133.048863</td>\n",
       "      <td>185.881683</td>\n",
       "      <td>208.283461</td>\n",
       "      <td>199.729818</td>\n",
       "      <td>231.931024</td>\n",
       "      <td>321.919245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>152.315462</td>\n",
       "      <td>125.099960</td>\n",
       "      <td>188.552380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>107.470926</td>\n",
       "      <td>137.840488</td>\n",
       "      <td>144.741148</td>\n",
       "      <td>139.642400</td>\n",
       "      <td>175.499288</td>\n",
       "      <td>262.297541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>107.470926</td>\n",
       "      <td>120.415946</td>\n",
       "      <td>133.048863</td>\n",
       "      <td>107.470926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.136243</td>\n",
       "      <td>97.467943</td>\n",
       "      <td>101.488916</td>\n",
       "      <td>128.257553</td>\n",
       "      <td>213.190056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>177.763888</td>\n",
       "      <td>183.983695</td>\n",
       "      <td>185.881683</td>\n",
       "      <td>137.840488</td>\n",
       "      <td>77.136243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.386128</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>78.740079</td>\n",
       "      <td>146.969385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>198.116128</td>\n",
       "      <td>204.939015</td>\n",
       "      <td>208.283461</td>\n",
       "      <td>144.741148</td>\n",
       "      <td>97.467943</td>\n",
       "      <td>27.386128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.370039</td>\n",
       "      <td>64.420494</td>\n",
       "      <td>131.339255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>197.484177</td>\n",
       "      <td>200.124961</td>\n",
       "      <td>199.729818</td>\n",
       "      <td>139.642400</td>\n",
       "      <td>101.488916</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>39.370039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.111026</td>\n",
       "      <td>155.884573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>227.156334</td>\n",
       "      <td>243.823707</td>\n",
       "      <td>231.931024</td>\n",
       "      <td>175.499288</td>\n",
       "      <td>128.257553</td>\n",
       "      <td>78.740079</td>\n",
       "      <td>64.420494</td>\n",
       "      <td>72.111026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143.527001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>311.126984</td>\n",
       "      <td>318.355148</td>\n",
       "      <td>321.919245</td>\n",
       "      <td>262.297541</td>\n",
       "      <td>213.190056</td>\n",
       "      <td>146.969385</td>\n",
       "      <td>131.339255</td>\n",
       "      <td>155.884573</td>\n",
       "      <td>143.527001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ID          382         384         249         386         145         330  \\\n",
       "ID                                                                            \n",
       "382    0.000000   71.763500   77.665951  152.315462  107.470926  177.763888   \n",
       "384   71.763500    0.000000  114.551299  125.099960  120.415946  183.983695   \n",
       "249   77.665951  114.551299    0.000000  188.552380  133.048863  185.881683   \n",
       "386  152.315462  125.099960  188.552380    0.000000  107.470926  137.840488   \n",
       "145  107.470926  120.415946  133.048863  107.470926    0.000000   77.136243   \n",
       "330  177.763888  183.983695  185.881683  137.840488   77.136243    0.000000   \n",
       "78   198.116128  204.939015  208.283461  144.741148   97.467943   27.386128   \n",
       "142  197.484177  200.124961  199.729818  139.642400  101.488916   40.000000   \n",
       "101  227.156334  243.823707  231.931024  175.499288  128.257553   78.740079   \n",
       "168  311.126984  318.355148  321.919245  262.297541  213.190056  146.969385   \n",
       "\n",
       "ID          78          142         101         168  \n",
       "ID                                                   \n",
       "382  198.116128  197.484177  227.156334  311.126984  \n",
       "384  204.939015  200.124961  243.823707  318.355148  \n",
       "249  208.283461  199.729818  231.931024  321.919245  \n",
       "386  144.741148  139.642400  175.499288  262.297541  \n",
       "145   97.467943  101.488916  128.257553  213.190056  \n",
       "330   27.386128   40.000000   78.740079  146.969385  \n",
       "78     0.000000   39.370039   64.420494  131.339255  \n",
       "142   39.370039    0.000000   72.111026  155.884573  \n",
       "101   64.420494   72.111026    0.000000  143.527001  \n",
       "168  131.339255  155.884573  143.527001    0.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test,index=data.index,columns=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_qaoa.utilities import distances_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "dist = pd.DataFrame(distance_matrix(data.values,data.values,p=2),\n",
    "                       index=data.index,columns=data.index)\n",
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From MAXCUT to QUBO\n",
    "With an understanding of the MAXCUT structure which produces our clustered output, we ask ourselves how we can turn what is effectively a graph problem into the setting of an optimization problem. The answer is to map our MAXCUT interpretation into a **Quadratic Unconstrainted Binary Optimization** ([QUBO](https://en.wikipedia.org/wiki/Quadratic_unconstrained_binary_optimization)) problem. QUBO problems attempt to minimize a quadratic polynomial with binary variables. Luckily, MAXCUT already has a well-known QUBO cost function. This cost function is sophisticated enough to allow for our pairwise distanes to be meaningfully included, as well as to allow for the inclusion of bias terms on individual samples. A more detailed explanation about the construction of this cost function is in the second notebook. <br><br>\n",
    "<center> $Cost=-\\sum_{\\langle i j\\rangle} J_{i j} \\sigma_{i} \\sigma_{j}-\\mu \\sum_{j} h_{j} \\sigma_{j}$ </center>\n",
    "\n",
    "To explain the notation:\n",
    "- $\\sigma_{i}$ is class (0 or 1) of sample $i$\n",
    "- $J_{i j}$ is the distance between sample $i$ and sample $j$\n",
    "- $h_{j}$ is a bias term on sample $j$ \n",
    "\n",
    "By convention, a negative sign is applied to the cost function, as above. In quantum mechanics we would denote thie function as $H(\\sigma)$. The symbol $H$ stands for *Hamiltonian*, which is an operator which acts as a sum of the energies of the system. For the scope of this notebook, thinking of $Cost$ as any traditional cost function which we want to minimize will serve us equally as valuable.\n",
    "\n",
    "***\n",
    "## Create the Hamiltonian\n",
    "Now we must use our data to create the cost function defined above. To make a Hamiltonian that is recognizable by pyQuil, we must use the pyQuil `PauliTerm` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquil.api import WavefunctionSimulator\n",
    "from pyquil.paulis import PauliSum, PauliTerm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `PauliTerm` object can be quadratic or of order one. In the case of it being quadratic, it  represents the relationship between any two samples of data. An order one `PauliTerm` would be an implementation of a bias term - a cost constraint which only affects one variable. Below we show some basic functionality of the `PauliTerm` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing a quadratic PauliTerm\n",
    "i = 3\n",
    "j = 6\n",
    "print('Distance between samples %d and %d: %.3f' %(i,j,dist.values[i][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the quadratic term we multiply two Paulis together. Each `PauliTerm` has an accompanying coefficient which is also multiplied. For simplicity's sake, we include the pairwise distance as a coefficient of one term, and make the other '1.0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term1 = PauliTerm(\"Z\",i,dist.values[i][j])\n",
    "term2 = PauliTerm(\"Z\",j,1.0) \n",
    "term = term1*term2\n",
    "print(term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to play with the number of `term2` to see how it affects the output of the cell.\n",
    "\n",
    "For those new to quantum, you're likely wondering what the purpose of the letter 'Z' is. It indicates that this `PauliTerm` is a Z operator.\n",
    "\n",
    "You may also note that our sample numbers, $i=3$ and $j=6$, have found their way into the printed output. Including $i$ and $j$ in each `PauliTerm` tells pyQuil which **qubit** the operation is applied to. \n",
    "```\n",
    "Z3*Z6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term1 = PauliTerm(\"Z\",0,) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that to make the Hamiltonian for our system we must iterate over each distance in our distance matrix, and assign it within a `PauliTerm` as the interaction strength between the appropriate qubits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pauli_list = list()\n",
    "m,n = dist.shape\n",
    "\n",
    "#pairwise interactions\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        if i < j:\n",
    "            term = PauliTerm(\"Z\",i,dist.values[i][j])*PauliTerm(\"Z\",j, 1.0) #we set the second term to 1, so we don't scale the distances\n",
    "            pauli_list.append(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamiltonian = PauliSum(pauli_list)\n",
    "print(hamiltonian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above exercise brings up an important limitation to our present QAOA approach. The number of datapoints we are able to use is limited by the number of qubits we have available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Hamiltonian To Clusters\n",
    "<br>\n",
    "<br>\n",
    "<center><img src=\"imgs/spins.png\"style=\"width:200px\"></center>\n",
    "<center><i> A depiction of the maxcut problem, displaying a cut which separates white and black vertices.</i></center>\n",
    "<br>\n",
    "<br>  \n",
    "\n",
    "\n",
    "\n",
    "It is possible to take inspiration from stati\n",
    "\n",
    "'optimize' such a problem to result in the best possible cut. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply QAOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the neccesary pyquil modules\n",
    "from forest_qaoa.qaoa.cost_function import QAOACostFunctionOnQVM, QAOACostFunctionOnWFSim\n",
    "\n",
    "# import the QAOAParameters that we want to demo\n",
    "from forest_qaoa.qaoa.parameters import GeneralQAOAParameters\n",
    "from forest_qaoa.vqe.optimizer import scipy_optimizer\n",
    "\n",
    "#Some utilities for time tracking and measuring our outcomes.\n",
    "import time\n",
    "from math import log\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the Problem Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 3\n",
    "end_time = 1\n",
    "iters = 500\n",
    "num_q = 10 #this number might be defined before your dataset\n",
    "#The hamiltonian is also a hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Parameters\n",
    "In this QAOA run, we will use `GeneralQAOAParameters`. This parameter class provides the most degrees of freedom for our optimizer to explore the energy landscape. Conversely, it also has the most parameters to optimize and thus will take longer to converge. \n",
    "\n",
    "To insantiate this parameter class, we need to pass in three separate lists of angles.\n",
    "- $\\vec{\\beta}$: every timestep requires 'nqubit' beta rotations. Thus there are $nqubit\\cdot timestep$ beta values.\n",
    "- $\\vec{\\gamma}_{pairs}$: there is a gamma rotation for every two-qubit interaction. A simple way to come up with this number is to measure the length of your hamiltonian subtracted by the number of single qubit bias terms in place.\n",
    "- $\\vec{\\gamma}_{singles}$: there is a gamma single rotation for each bias term included in the hamiltonian.\n",
    "\n",
    "We randomly generate these lists as their initial starting states are somewhat redunant. They will be optimized over 100s of iterations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = [round(val,1) for val in np.random.rand(timesteps*num_q)]\n",
    "gammas_singles = [round(val,1) for val in np.random.rand(0)] #we don't want any bias terms\n",
    "gammas_pairs = [round(val,1) for val in np.random.rand(timesteps*len(hamiltonian))]\n",
    "\n",
    "hyperparameters = (hamiltonian, timesteps)\n",
    "parameters = (betas, gammas_singles, gammas_pairs)\n",
    "\n",
    "params = GeneralQAOAParameters(hyperparameters, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the simulator, make sure you are running rigetti's QVM and Quil Compiler\n",
    "### First QAOA Run: 3 Timesteps, 500 Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the WavefunctionSimulator from pyQuil\n",
    "sim = WavefunctionSimulator()\n",
    "cost_function = QAOACostFunctionOnWFSim(hamiltonian,\n",
    "                                            params=params,\n",
    "                                            sim=sim,\n",
    "                                            return_standard_deviation=True,\n",
    "                                            noisy=False,\n",
    "                                            log=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "res = scipy_optimizer(cost_function, params.raw(), epsilon=1e-3,\n",
    "                          maxiter=iters)\n",
    "print('Run complete!\\n','Runtime:','{:.3f}'.format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_lowest_state(probs):\n",
    "    index_max = max(range(len(probs)), key=probs.__getitem__)\n",
    "    string = '{0:0'+str(int(log(len(probs),2)))+'b}'\n",
    "    string = string.format(index_max)\n",
    "    return [int(item) for item in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(wave_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_func = cost_function.get_wavefunction(params.raw())\n",
    "lowest = return_lowest_state(wave_func.probabilities())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_clusters = [1 if val else 0 for val in labels] \n",
    "print('True Labels of samples:',true_clusters)\n",
    "print('Lowest QAOA State:',lowest)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(lowest,true_clusters)\n",
    "print('Accuracy of Original State:',acc*100,'%')\n",
    "\n",
    "#Account for the complement bit string in case a class-swap\n",
    "final_c = [0 if item == 1 else 1 for item in lowest]\n",
    "\n",
    "acc_c = accuracy_score(final_c,true_clusters)\n",
    "print('Accuracy of Complement State:',acc_c*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can analyze the optimizer to see whether or not our QAOA run converged. For the full message, run:\n",
    "```python\n",
    "print(res)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cost Function Value:', res.fun)\n",
    "print('Converged?:',res.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we did not converge. Let's tighten up our operations by wrapping our QAOA runs in a function and increase the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_qaoa(hamiltonian,params, timesteps=2,end_time=1,max_iters=150,init_state=None):    \n",
    "    sim = WavefunctionSimulator()\n",
    "    cost_function = QAOACostFunctionOnWFSim(hamiltonian,\n",
    "                                            params=params,\n",
    "                                            sim=sim,\n",
    "                                            return_standard_deviation=True,\n",
    "                                            noisy=False,\n",
    "                                            log=[],\n",
    "                                            init_state=init_state)\n",
    "    \n",
    "    res = scipy_optimizer(cost_function, params.raw(), epsilon=1e-3,\n",
    "                          maxiter=max_iters)\n",
    "    \n",
    "    return cost_function.get_wavefunction(params.raw()), res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "wave_func , res = run_qaoa(hamiltonian,params,timesteps=2,max_iters=1000)\n",
    "print('Run complete\\n','Runtime:','{:.3f}'.format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest = return_lowest_state(wave_func.probabilities())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_clusters = [1 if val else 0 for val in labels] \n",
    "print('True Labels of samples:',true_clusters)\n",
    "print('Lowest QAOA State:',lowest)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(lowest,true_clusters)\n",
    "print('Accuracy of Original State:',acc*100,'%')\n",
    "\n",
    "#Account for the complement bit string in case a class-swap\n",
    "final_c = [0 if item == 1 else 1 for item in lowest]\n",
    "\n",
    "acc_c = accuracy_score(final_c,true_clusters)\n",
    "print('Accuracy of Complement State:',acc_c*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[data.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your own performance will vary based on which Pokemon were randomly selected from each class. Results can be improved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA(n_components=5).fit(data).explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_results(data, pca):    \n",
    "    # Dimension indexing\n",
    "    dimensions = ['PC-{}'.format(i) for i in range(1,len(pca.components_)+1)]\n",
    "    \n",
    "    # PCA components\n",
    "    components = pd.DataFrame(np.round(pca.components_, 4), columns = data.keys()) \n",
    "    components.index = dimensions\n",
    "\n",
    "    # PCA explained variance\n",
    "    ratios = pca.explained_variance_ratio_.reshape(len(pca.components_), 1) \n",
    "    variance_ratios = pd.DataFrame(np.round(ratios, 4), columns = ['Explained Variance']) \n",
    "    variance_ratios.index = dimensions\n",
    "\n",
    "    # Create a bar plot visualization\n",
    "    fig, ax = plt.subplots(figsize = (14,8))\n",
    "\n",
    "    # Plot the feature weights as a function of the components\n",
    "    components.plot(ax = ax, kind = 'bar')\n",
    "    ax.set_ylabel(\"Feature Weights\") \n",
    "    ax.set_xticklabels(dimensions, rotation=0)\n",
    "\n",
    "    # Display the explained variance ratios# \n",
    "    for i, ev in enumerate(pca.explained_variance_ratio_): \n",
    "        ax.text(i-0.40, ax.get_ylim()[1] + 0.05, \"Explained Variance\\n %.4f\"%(ev))\n",
    "    \n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    \n",
    "    # Return a concatenated DataFrame\n",
    "    return pd.concat([variance_ratios, components], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results = pca_results(data, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function can create the loading plot from PCA along any PCs indicated in components = list()\n",
    "def loading_plot_color(reduced_data, pca, components=[1,2]):\n",
    "    fig, ax = plt.subplots(figsize = (10,8))\n",
    "    # scatterplot of the reduced data \n",
    "    pc1 = 'PC-'+str(components[0])\n",
    "    pc2 = 'PC-'+str(components[1])\n",
    "    \n",
    "    coords_x0, coords_x1, coords_y0, coords_y1 = list(), list(), list(), list()\n",
    "    \n",
    "    for i, target in enumerate(reduced_data['label']):\n",
    "        if target == 0:\n",
    "            print('yes')\n",
    "            coords_x0.append(reduced_data.loc[:,pc1][i])\n",
    "            coords_y0.append(reduced_data.loc[:,pc2][i])\n",
    "        else:\n",
    "            coords_x1.append(reduced_data.loc[:,pc1][i])\n",
    "            coords_y1.append(reduced_data.loc[:,pc2][i])\n",
    "    \n",
    "    #Plot class 0\n",
    "    ax.scatter(x=coords_x0, y=coords_y0, \n",
    "               edgecolors='b',color='blue', s=70, alpha=0.75)\n",
    "    \n",
    "    #Plot class 1\n",
    "    ax.scatter(x=coords_x1, y=coords_y1, \n",
    "               edgecolors='g',color='green', s=70, alpha=0.75)\n",
    "\n",
    "    feature_vectors = pca.components_.T\n",
    "    # using scaling factors to make the arrows\n",
    "    arrow_size, text_pos = 7.0, 8.0,\n",
    "\n",
    "    # projections of the original features\n",
    "    for i, v in enumerate(feature_vectors):\n",
    "        ax.arrow(0, 0, arrow_size*v[components[0]-1], arrow_size*v[components[1]-1], head_width=0.2, head_length=0.15, linewidth=1, color='red',alpha=0.5)\n",
    "        ax.text(v[components[0]-1]*text_pos, v[components[1]-1]*text_pos, data.columns[i], color='black', ha='center', va='center', fontsize=18)\n",
    "        \n",
    "    ax.set_xlim([-5,5])\n",
    "    ax.set_ylim([-5,5])\n",
    "    ax.set_xlabel(pc1, fontsize=14)\n",
    "    ax.set_ylabel(pc2, fontsize=14)\n",
    "    ax.set_title(\"Feature projection along the \" + pc1 + ' by ' +pc2 + ' plane.', fontsize=16);\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 6)\n",
    "reduced_data = pd.DataFrame(pca.fit_transform(data), \n",
    "                            columns = ['PC-{}'.format(i) for i in range(1,len(pca.components_)+1)])\n",
    "reduced_data['label'] = [1 if val else 0 for val in labels.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_plot_color(reduced_data, pca);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
